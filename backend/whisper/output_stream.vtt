WEBVTT

00:01.280 --> 00:03.747
So, schönen guten Tag.

00:03.767 --> 00:07.116
Wir machen weiter mit dem Thema Betriebssysteme.

00:07.136 --> 00:15.458
Und ich bin gerade ein bisschen erstaunt, weil unsere Tele-Taske-Gänge nicht da ist, um das aufzuzeichnen, aber dann ist es halt so.

00:18.678 --> 00:19.760
Wo waren wir stehen geblieben?

00:19.820 --> 00:24.627
Wir hatten ja so ein bisschen darüber gesprochen, was ist ein Betriebssystem?

00:24.667 --> 00:26.309
Was sind die Aufgaben von einem Betriebssystem?

00:26.329 --> 00:29.795
Warum lohnt sich das, sich damit auseinanderzusetzen?

00:29.855 --> 00:37.406
Und jetzt gehen wir weiter und reden ein bisschen über die Frage, was ist eigentlich ein Computer?

00:37.426 --> 00:39.829
Welche Sorten von Computern gibt es?

00:39.849 --> 00:42.634
Womit sollten wir uns beschäftigen?

00:42.674 --> 00:46.179
Womit beschäftigen wir uns konkret in dieser Lehrveranstaltung?

00:46.199 --> 00:46.980
Danach werden wir

00:47.973 --> 00:53.140
ganz oberflächlich so ein paar Ideen ansprechen, die in Betriebssystemen implementiert sind.

00:53.160 --> 00:57.346
Prozesse, das klang letztes mal schon an, waren Programme in Ausführung.

00:57.387 --> 01:04.977
Wir werden ein bisschen uns Gedanken machen, wie man den Speicher aufteilen könnte, wenn man mehrere Programme gleichzeitig laufen lassen will und so weiter.

01:05.018 --> 01:13.710
Aber schauen wir erst mal, worüber wir eigentlich reden, also wir haben hier

01:14.298 --> 01:18.109
So eine Einteilung und hier steht irgendwie traditional in general purpose.

01:18.129 --> 01:25.050
Das ist glaube ich das, was wir als Schreibtisch Betriebssystem im Notebook Computer und so weiter sehen.

01:26.363 --> 01:27.886
Das ist Interessante hier.

01:27.926 --> 01:29.949
Man weiß eigentlich nicht, was der Nutzer will.

01:29.969 --> 01:37.442
Also wir haben Leute, die schreiben eine Textverarbeitung, wir haben Leute, die spielen ein Spiel, wir haben welche, die machen irgendwie wissenschaftliches Rechnen.

01:37.502 --> 01:41.028
Das heißt, hier muss man so eine Balance treffen.

01:41.689 --> 01:43.953
Beim mobilen Geräten ist die Geschichte ganz anders.

01:43.993 --> 01:47.459
Da muss man vor allen Dingen die Sprache, Sprachübertragung bedienen können.

01:47.499 --> 01:50.704
Das sind 64 Kilometer pro Sekunde, das ist nicht so sehr schwer.

01:50.724 --> 01:52.287
Man möchte heutzutage auch noch

01:52.267 --> 01:56.591
Ein bisschen Internet machen, ein bisschen Oberfläche programmieren.

01:56.651 --> 02:00.735
Und vor allen Dingen muss man sich Gedanken machen, dass der Strom lang erreicht, nicht?

02:00.755 --> 02:05.019
Also, wie kann man denn Programme so schreiben, dass sie möglichst wenig Energie verbrauchen?

02:06.160 --> 02:07.702
Sie erinnern sich an GDS.

02:07.722 --> 02:09.964
Da haben Sie etwas über Befehlssätze gelernt.

02:10.004 --> 02:19.012
Da haben Sie gelernt, dass es irgendwie eine aratmetisch-logische Einheit gibt, dass es Transportbefehle gibt, dass es aratmetisch-logische Befehle gibt, Gleitkommarbefehle gibt.

02:19.032 --> 02:19.793
Dann gab es irgendwie

02:20.768 --> 02:25.902
Sprungsprünge nicht, also die Steuerung vom Ablauf.

02:26.062 --> 02:34.525
Und jetzt kann man sich fragen, kann man denn Dinge auf verschiedene Weise rechnen und dabei unterschiedlich viel Strom verbrauchen?

02:35.669 --> 02:38.993
Und ja, da gibt es Möglichkeiten.

02:39.654 --> 02:42.779
Also eine Fragestellung, die wir uns hier nicht so genau angucken.

02:42.799 --> 02:48.386
Wie kommt man denn mit begrenzten Ressourcen und Energiebedarf besser um die Ecke?

02:48.406 --> 02:49.107
Das ist ein Thema.

02:49.127 --> 02:52.251
Wenn Sie da Interesse haben, kommen Sie im Masterstudium bei uns wieder vorbei.

02:52.271 --> 02:57.218
Da heißt die Veranstaltung dann VVES, verlässliche verteilte eingebettete Systeme.

02:57.238 --> 03:00.022
Und dort beschäftigen wir uns mit solchen Fragen.

03:00.082 --> 03:00.883
Kleinen Server.

03:02.365 --> 03:09.937
Das ist die Idee, dass man halt nicht alles in einem System baut, sondern dass man sich abstürzt auf Dienste, die andere anbieten.

03:09.957 --> 03:11.599
peer-to-peer ist ganz ähnlich.

03:11.619 --> 03:14.043
Bei kleinen Server ist klar, der Server hat eine Rolle.

03:14.083 --> 03:17.548
Das ist zum Beispiel ein Fileserver oder das ist ein E-Mail-Server.

03:17.568 --> 03:25.200
Bei peer-to-peer möchte man keine ausgezeichneten Knoten haben, sondern alle sollen und wie das gleiche können.

03:25.788 --> 03:27.891
Cloud Computing, was war das?

03:27.911 --> 03:32.678
Das war die Idee, dass man Rechenleistung genauso wie Strom aus der Steckdose anguckt.

03:32.718 --> 03:51.825
Also wenn Sie heute nach China fahren und sich dort eine Neubersiedlung angucken, dann haben die in ihren Wohnungen nicht bloß irgendwie ein Stromkabel, sondern die haben auch noch einen Kabel an, dass man eine Tastatur und ein Bildschirm anstecken kann und dahinter ist ein Computer irgendwo.

03:51.845 --> 03:53.888
Natürlich ideal, wenn man das in einer

03:54.290 --> 04:00.347
Wenn man so ein bisschen überwacher sein will, dann weiß man genau, was die Leute benutzen.

04:00.367 --> 04:02.734
So was ähnliches gab es bei den Franzosen auch schon mal.

04:02.754 --> 04:09.312
Das heißt, man benutzt Rechenleistung, so wie Strom aus der Steckdose, man bezahlt so viel, wie man verbraucht und mehr eben nicht.

04:09.292 --> 04:12.195
Wie muss man sich das hierzulande vorstellen?

04:12.215 --> 04:14.157
Sie haben vielleicht schon mal von E-Shelter gehört.

04:14.177 --> 04:16.800
E-Shelter ist ein großer Rechenzentrumsbetreiber.

04:16.860 --> 04:28.573
Und wenn sie zu Amazon gehen, Amazon hat 70% im Cloud-Markt, nicht Amazon Web Services, weil sie gehen zu Microsoft, da heißt es Azure, oder sie gehen zu Google App Engine.

04:28.593 --> 04:32.177
Diese ganzen Hyperscaler, die rechnen letztlich in Rechenzentren

04:32.157 --> 04:35.180
von der Firma E-Shelter hier in Deutschland.

04:35.200 --> 04:37.423
In Frankfurt gibt es vier Stück, in Berlin gibt es eins.

04:37.463 --> 04:47.614
Das ist am Kraftwerk Reuter aufgebaut und das Ding hat 10 megawatt Anschlussleistung, ne, 10 megawatt Kühlleistung, 13 megawatt Anschlussleistung.

04:47.654 --> 04:54.001
Das ist also gleich neben Kraftwerk gebaut, gleich an der Havel, damit man gut kühlen kann und auf geht's.

04:54.021 --> 04:58.266
Und wenn Sie sagen, na ja, wie ist das jetzt mit den

04:58.246 --> 05:07.627
Behördlichen Leistungen, also e-government, elektronisches Grundbuch, Polizeifunk, Brandenburg, das rechnet dort auch mit.

05:07.647 --> 05:18.010
Also wir haben heute so eine starke Konstentration auf wenige Leistungsfähige Rechenzentren und sind es gewohnt, dass die halt verlässlich Dienst anbieten.

05:17.990 --> 05:27.190
verlässlich Dienstanbieten, das fängt damit an, dass man die nicht erkennt von außen, kritische Infrastruktur.

05:27.230 --> 05:36.150
Die haben Anbindung an mir, ihre Stromprovider, an verschiedene Versorger und sie haben natürlich auch manchfache Anbindung an das Internet.

05:37.463 --> 05:49.440
Also Cloud Computing ist letztlich kein Betriebssystem Thema in erster Linie, sondern ist erst mal ein geschäftliches Thema, wo man sagt, wir wollen die Leistung so anbieten, wie sie benutzt werden.

05:49.480 --> 05:58.493
Also man soll es halt wie Strom aus der Steckdose pay as you go, so viel bezahlen wir immer benutzt, mehr nicht.

05:58.553 --> 06:01.918
Ist Cloud Computing eine Möglichkeit, Kosten zu senken?

06:01.898 --> 06:07.246
Naja, ich weiß nicht, wer von Ihnen Backups macht von seinen Daten?

06:07.266 --> 06:09.249
Gibt es solche Menschen?

06:09.269 --> 06:11.793
Fotos, machen Sie auch Backups von Fotos?

06:11.813 --> 06:12.814
Ja, der Super-Gau nicht.

06:12.854 --> 06:17.020
Also jemand bricht bei Ihnen ein und klaut diese Festplatte, auf der die ganzen Fotos sind.

06:17.040 --> 06:22.068
Wenn Sie Glück haben, haben Sie noch eine zweite Festplatte bei Ihren Eltern irgendwie ein Stück weit weg.

06:22.128 --> 06:24.852
Aber wir haben schon mal überräumliche Distance beim Backup nachgedacht.

06:25.608 --> 06:28.414
Ja, weniger.

06:28.434 --> 06:38.176
Das ist sicherlich eine Stelle, wo man Kosten spart, wenn man auf solche Cloud-Lösungen zurückgreift, weil man sich halt keine Gedanken um die Administration machen muss, und die machen es richtig.

06:38.197 --> 06:41.524
Da kann man davon ausgehen.

06:41.825 --> 06:50.560
Ansonsten ist es so, dass der Gedanke, man spart immens Kosten, geführend ist, sondern man hat eher das Phänomen, dass man so ein Wenderlock in hat.

06:50.580 --> 07:00.256
Man hat dann halt einen Anbieter, der hat API's und Schnittstellen und darauf fährt man dann ab und der Wechsel zu einem anderen Anbieter ist gar nicht so einfach.

07:00.316 --> 07:06.246
Was nebenbei bei Cloud Computing auch noch ein Thema ist, Daten runterladen ist in der Regel billig, Daten hochladen ist teuer.

07:06.698 --> 07:14.468
Das geht so weit, dass die Cloud-Anbieter einen Interface haben, wo man ihnen eine Festplatte hinschicken kann.

07:15.449 --> 07:18.793
Also die Post ist dann der einfachste Weg, Daten da hochzuladen.

07:20.916 --> 07:30.968
Alles Dinge, die wir in diesem Teilprogramm Betriebstemo 1 nicht besprechen, sondern die kommen teilweise in Betriebstemo 2 vor, aber eigentlich dann eher im Masterstudium.

07:31.488 --> 07:37.674
Und Drilltime Embedded, naja, da war die Frage, wann sind wir denn fertig mit unserer Berechnung?

07:37.694 --> 07:40.878
Können wir das Ganze auch ohne Bildschirmen, können wir das ohne Nutzer-Eingaben machen?

07:40.918 --> 07:42.439
Wie baut man solche Systeme?

07:42.459 --> 07:46.383
Auch ein Thema, was wir primär im Masterstudium angucken.

07:46.443 --> 07:56.153
Aber es ist, glaube ich, ganz klar, während wir hier oben so ein Fairness als ein Ziel haben, also jeder soll auf die gleiche Weise bedient werden, haben wir hier unten ganz klare Vorstellungen.

07:56.193 --> 07:58.776
Es gibt dann eine Aufgabe, die müssen wir erledigen.

07:58.816 --> 08:00.718
Im Auto gibt es

08:01.205 --> 08:09.235
Wenn Sie so ein moderneres Auto angucken, was rote Lichter anmacht, wenn Sie die Tür aufmachen, dahinter stecken Leuchtioden, schon klar, ne?

08:09.255 --> 08:11.958
Aber jeder von diesen Leuchtioden hat einen eigenen Prozessor.

08:11.998 --> 08:22.251
Und zwar deshalb, weil diese Biester so eine hohe Streuung haben und auf der anderen Seite das Rot, was da rauskommt, das verlangt der TÜV-Halt, ja, die gewisse Wellenlänge haben muss.

08:22.923 --> 08:35.522
Also wenn Sie da nach Bochengen, da gibt es eine Firma der SLMOS und die bauen solche kleinen Prozessoren sozusagen für jede von diesen signifikanten Leuchten, die unten einnehmen.

08:35.562 --> 08:40.569
Auch das sind Real-Time Embedded Systeme und natürlich ist klar, dass da Fairness generell mehr spielt.

08:40.709 --> 08:48.120
Da gibt es genau einen Job, den man darauf laufen lassen muss, nämlich die Farbtemperatur von diesem Ding da bedienen.

08:50.007 --> 08:56.057
Also was ein Betriebssystem eigentlich machen muss, hängt ab davon, wo was einsetzen, schon klar.

08:56.077 --> 09:01.826
Und wir reden über solche Standalone General Purpose Maschinen.

09:01.866 --> 09:10.800
Früher waren die halt wirklich ganz für sich, heute sind sie immer am Internet und das heißt, wir müssen immer uns irgendwie mit dem

09:11.675 --> 09:15.661
Protokollen des Internets beschäftigen, TCP IP.

09:15.681 --> 09:18.446
Wer von Ihnen hat schon mal von TCP IP gehört?

09:18.466 --> 09:18.526
Ja.

09:18.546 --> 09:22.372
Wer hat schon mal eine Socket Anwendung programmiert?

09:22.392 --> 09:23.634
Okay, ein paar Wenige.

09:23.654 --> 09:24.435
Gut.

09:24.455 --> 09:31.667
Nicht also... Wir sind gewohnt, dass wir den Krempel irgendwie benutzen und man kann HTTPS eintippen und dann denkt man, das ist jetzt sicher.

09:31.687 --> 09:32.909
Aber warum eigentlich?

09:32.949 --> 09:35.653
Was steckt denn dahinter an Protokollen?

09:35.673 --> 09:39.319
Auch kein spezifisches Betriebssysteme-Thema, aber wir werden das ein bisschen streiten.

09:42.421 --> 09:44.067
Mobile Umgebungen?

09:44.148 --> 09:52.380
Naja, da ist das Thema, welche Sorten Netzwerk haben wir denn eigentlich die spannende Geschichte und wie programmiert man einen Touchscreen?

09:53.677 --> 10:00.190
Gucken wir uns vielleicht in Übungen an, aber eigentlich auch noch am Rande und bei kleinen Server Umgebungen.

10:00.210 --> 10:02.615
Na ja, da reden wir eigentlich über verteilte Systeme.

10:02.635 --> 10:06.483
Dafür gibt es eine eigene Lehrveranstaltung.

10:06.503 --> 10:12.715
Was wir als typische Dienste haben, sind Computedienste, sind File Server Dienste.

10:13.184 --> 10:20.845
Gab's exotische Entwicklungen nicht also beispielsweise gibt's ein Betriebssystem, das heißt am über dort war die Idee, dass man sagt wir bauen.

10:20.865 --> 10:29.488
Fileserver die unveränderlich Datenspeicher, also die haben das Bulletserver genannt so ähnlich wie man mit einer.

10:29.671 --> 10:37.442
mit einer Flinte und die Löcher in eine Papierscheibe schießen kann, kann man in diesen Server Daten reinschreiben, aber niemals verändern.

10:38.404 --> 10:42.389
Das heißt, anstelle sie zu verändern, wird man eine neue Kopie schreiben.

10:42.409 --> 10:50.962
Und das ist ein Schema, was man in manchen Dateisystemen heute wieder findet.

10:51.082 --> 10:56.910
Und peer-to-peer, wie gesagt, da ist die Idee, dass wir kleinen Server nicht unterscheiden.

11:00.400 --> 11:04.544
Genau, Cloud Computing.

11:04.564 --> 11:09.449
Dafür gibt es einen Lehrveranstaltungen Master und Embedded.

11:09.469 --> 11:11.632
Auch da habe ich schon auf die Zukunft verwiesen.

11:13.273 --> 11:15.336
Was machen nun Betriebssysteme?

11:15.376 --> 11:17.157
Und da gucken wir ein bisschen in die Geschichte.

11:17.197 --> 11:18.859
Also wie hat es angefangen?

11:18.879 --> 11:24.885
Angefangen hat es halt mit ... Wie hat eigentlich ein Computer erfunden?

11:24.905 --> 11:25.446
Wissen Sie es noch?

11:27.130 --> 11:33.237
Also wenn Sie hier, sagen wir mal, in Brandenburg, also in Berlin sind, dann gibt es eine richtige Antwort, ja?

11:33.257 --> 11:34.138
Konkurren wir zu Sie?

11:34.158 --> 11:35.740
Das ist schon mal eine richtige Antwort.

11:35.760 --> 11:42.348
Gibt noch mehr richtige Antworten, ja?

11:42.408 --> 11:44.330
Okay, da kann man noch ein bisschen weiter zurückgehen.

11:44.350 --> 11:47.134
Da können wir zu Shouts Babbage gehen und zu Analytical Engine.

11:47.154 --> 11:52.440
Das war irgendwie in den 1600er Jahren und da gibt es die Era Loveless, die als erste Programmiererin auftrat, nicht?

11:52.460 --> 11:54.823
Und deshalb gibt es die Programmiersprache Ada.

11:54.843 --> 11:54.943
Okay.

11:55.126 --> 11:59.459
Aber reden wir mal um moderne Computer, wie wir sie heute kennen.

11:59.500 --> 12:05.097
Die sind sozusagen dreimal erfunden worden, nämlich hier in Konvatsuse.

12:05.157 --> 12:08.427
Und in Amerika gibt es Eckhart und Morley und den John von Neumann.

12:09.723 --> 12:16.276
Und in England wurde auch nochmal ein Computer erfunden in Cambridge.

12:16.297 --> 12:18.822
Also es passiert alles ziemlich gleichzeitig.

12:18.862 --> 12:26.297
Wenn Sie schon von Neumann gehört haben, dann haben Sie sozusagen die erste Lektion für Ihr Studium schon gelernt.

12:26.463 --> 12:34.322
weil Eckhardt und Morley haben eigentlich die Arbeit gemacht und der von Neumann hat den Report geschrieben und alle reden heute über den John von Neumann-Computer.

12:34.362 --> 12:38.412
Von Neumann-Computer ist gesetzt als Wort, aber in Wirklichkeit hat er es gar nicht gemacht.

12:38.873 --> 12:41.940
Der war aber trotzdem ein cooler Typ, also der kommt aus Budapest ursprünglich.

12:42.578 --> 12:49.030
Und ich glaube, in der Abiturklasse, wo der Herr kam, da waren zwei oder drei Nobelpreisträger.

12:49.050 --> 12:51.735
Also die hatten da was Spezielles im Futter offenbar.

12:51.755 --> 12:55.442
Und dann war er aber eine Weile Assistent an der Humboldt Uni, John von Neumann.

12:55.522 --> 13:00.812
Deshalb heißt es Informatikgebäude, der Humboldt in Adlers-Hofdraußen von Neumann Gebäude.

13:00.832 --> 13:02.595
Das war in 1930er Jahren.

13:02.615 --> 13:05.160
Dann kam die Nazis an die Macht.

13:05.613 --> 13:07.756
Und dann hat der das Weite gesucht.

13:07.776 --> 13:15.205
Also, da gab es einen Gewalt in Adalas, ein Thema, was man vielleicht im Kopf haben muss bei der nächsten Wahl, wo man seine Kreuze richtig macht.

13:15.225 --> 13:17.208
Das hat schon einmal nicht funktioniert.

13:17.268 --> 13:21.313
Und dann ging der halt nach Amerika.

13:21.333 --> 13:24.237
Und da war er derjenige, der die Berichte geschrieben hat.

13:24.257 --> 13:29.164
Also, Sie merken sich wenigstens, wenn Sie an irgendeinem Projekt mitmachen, dann schreiben Sie darüber.

13:29.184 --> 13:32.147
Sehen Sie zu, dass auf dem Publikation Ihr Name mit drauf steht.

13:32.167 --> 13:34.911
Die anderen Sachen können sich auch alle merken.

13:37.422 --> 13:40.465
Der Konrad Zuse hat ja noch mehr erfunden.

13:40.485 --> 13:43.349
Der hat ja nicht bloß ein Computer erfunden, sondern auch die erste Programmiersprache.

13:43.369 --> 13:47.473
Weißt jemand, wie die heißt?

13:47.493 --> 13:48.755
Plan-Calcul.

13:48.775 --> 13:50.016
Können Sie mal googeln.

13:50.036 --> 13:54.301
Gibt es einen Kollegen, Raul Rocher, das heißt ja einer FU, war der eine Weile.

13:54.321 --> 13:56.183
Die haben einen Simulator gemacht für Plan-Calcul.

13:56.203 --> 13:57.905
Da können Sie Programme schreiben mit Plan-Calcul.

14:00.248 --> 14:02.130
Bloß mal so eine Größenordnung.

14:02.262 --> 14:08.992
Wenn Sie ins Museum für Verkehr und Technik gehen, da sehen Sie die Z1, glaube ich, so eine mechanische Maschine.

14:09.012 --> 14:13.659
Die hat auch wirklich eine Verklemmung, also ein Deadlock.

14:13.699 --> 14:18.106
Da sind einfach mechanische Platten verklemmt gerade, die kann nicht weiterrechnen.

14:18.666 --> 14:21.290
Aber im Prinzip haben die das Ding nachgebaut, kann man auch betreiben.

14:21.310 --> 14:31.746
Die Z3 und Z4 waren eine relebasierte Rechner und die hatten dann eine Speicherkapazität von

14:31.726 --> 14:35.370
48 Worten.

14:35.390 --> 14:41.616
Also nicht 48 Kilobyte oder Megabyte oder Gigabyte, sondern 48 Worte.

14:41.776 --> 14:44.359
Und sie hatten aber schon dieses Story-Programm-Concept.

14:44.379 --> 14:48.844
Also das heißt, wir hatten im gleichen Speicher die Daten und das Programm.

14:48.984 --> 14:57.733
Sie erinnern sich an GDS, das war die Geschichte, dass man den Dingern nicht ansieht, sind es jetzt Daten aus dem Programm, sondern es fängt von der Interpretation ab.

14:58.456 --> 15:01.559
Wie kommen wir jetzt mit 48 Worten klar?

15:01.579 --> 15:04.302
Da war diese Idee mit den selbstmodifizierenden Programmen.

15:04.322 --> 15:11.410
Anstelle von Schleifen, verändern wir einfach das Programm, sodass der nächsten iteration was anderes passiert als bei der vorherigen.

15:12.731 --> 15:17.897
Das ist heute nicht mehr populär, selbstmodifizierender Code wird von Betriebssystemen sogar unterbunden.

15:17.937 --> 15:22.962
Da gibt es nämlich ein sogenanntes Feature, das heißt Data Execution Prevention, wo man dafür sorgt, dass

15:23.718 --> 15:29.627
Speicherseiten, die als Daten geflaggt sind, auf keinen Fall ausgeführt werden können, weil man denkt, das ist ein Virus oder sowas.

15:30.097 --> 15:33.521
Aber das war damals Mode.

15:33.541 --> 15:38.447
Und es war klar, in diesem Rechner mit den 48 Worten, da passt ein Programm rein schon klar.

15:40.529 --> 15:43.032
Das heißt, wie sieht so ein Programmlauf aus?

15:43.072 --> 15:44.234
Historisch.

15:44.254 --> 15:46.496
Man hat Eingabendaten.

15:46.516 --> 15:49.500
Die musste man in den Rechner reinfüttern.

15:49.560 --> 15:52.663
Und dann hat man Ausgabendaten produziert.

15:52.703 --> 15:54.906
Eingabendaten in Form von Lochkarten.

15:54.970 --> 15:56.332
Wir hat es erfunden, die IBM.

15:56.372 --> 15:59.196
Das ist in unserer Branche immer die richtige Antwort.

15:59.336 --> 16:02.641
Wenn jemand fragt, wer hat es erfunden, können Sie immer sagen IBM.

16:02.681 --> 16:05.224
In dem Fall war es die deutsche Hollerit AG.

16:05.244 --> 16:09.049
Und die deutsche Hollerit wurde später von einer IBM aufgekauft.

16:11.332 --> 16:12.774
Das heißt, wir haben Lochkarten.

16:12.814 --> 16:16.620
Wir rechnen eine Weile rum und wir produzieren wieder Lochkarten.

16:16.640 --> 16:19.183
Haben Sie schon mal von Heapsort gehört?

16:19.223 --> 16:22.548
Und sich gewundert, warum dieser Algorithmus so komisch funktioniert?

16:22.588 --> 16:24.150
Warum das Stapel eine Rolle spielen?

16:24.957 --> 16:26.420
Jetzt wissen sie es.

16:26.460 --> 16:30.869
Heapsort ist zu einer Zeit entwickelt worden, als man halt Lochkartenstapel hatte.

16:30.909 --> 16:38.784
Und da war es einfach, einen neuen Stapel zu produzieren und den dann wieder als Eingabestapel weiterzuverarbeiten und so weiter und dann auf diese Weise ihre Riterationen zu bauen.

16:39.606 --> 16:43.614
Also, ganz am Anfang war es einfach.

16:43.634 --> 16:46.780
Der Rechner war super teuer, viel wertvoller als der Mensch.

16:47.587 --> 16:51.274
Man musste einen Job laufen lassen, weil mehr passt sowieso nicht rein.

16:51.334 --> 16:56.164
Und der Job bestand darin, dass man Eingabedaten gelesen hat.

16:56.184 --> 16:58.007
Das ist das sogenannte E-Fahr-Prinzip.

16:58.027 --> 16:59.871
Haben Sie vielleicht schon mal gehört?

16:59.911 --> 17:02.236
Eingabe, Verarbeitung, Ausgabe.

17:02.256 --> 17:05.622
Können Sie immer sagen.

17:05.642 --> 17:09.510
Wir lesen also Lochkarten ein, wir rechnen eine Weile rum und wir tun die wieder raus.

17:09.592 --> 17:14.622
Und dann kam es schon den nächsten Schritt, nämlich dieses Thema Multi-Programmierung.

17:14.642 --> 17:17.447
Stapelverarbeitung heißt Batch-Shop Processing, nicht auf Englisch.

17:17.467 --> 17:22.958
Also manchmal ist es gut, die Deutschen wollte sich auch zu sagen, damit man einfach besser begreift, was los ist.

17:22.978 --> 17:25.002
Da wurden halt Lochkartenstapel verarbeitet.

17:24.982 --> 17:32.552
Und Multi-Programmierung war dann der nächste Streich, dass man gesagt hat, okay, jetzt sind unsere Computer so groß, dass wir mehr als ein Programm darin unterbringen.

17:32.572 --> 17:36.737
Das passierte so Anfang der 60er Jahre.

17:36.757 --> 17:41.964
Also, wenn wir schon mal über Eckart und Morley reden, die hatten ja dann schon einen Röhrenbasiertenrechner.

17:41.984 --> 17:44.627
Und da kommt ja auch dieser Begriff Back her.

17:44.607 --> 17:49.656
Weil, wenn sie schon mal in New Jersey waren, dann wissen sie, die haben ganz viel umgeziefer.

17:49.716 --> 17:53.262
Und die hatten halt das Fenster auf der Hitze halber.

17:53.283 --> 17:58.091
Und da sind natürlich Käfer reingekommen und an die Röhren angeklatscht und daraufhin die Röhren kaputt.

17:58.191 --> 18:01.958
Das war ein Back, also da kommt der Computer Back her.

18:04.840 --> 18:07.965
Wie gesagt, zu der Zeit war es dann schon möglich, mehrere Programme laufen zu lassen.

18:07.985 --> 18:10.389
Und die Frage ist jetzt, wie können wir die gegeneinander isolieren?

18:10.449 --> 18:13.213
Das ist ein Thema, da hatten wir letztens schon mal ganz kurz zurückgesprochen.

18:13.273 --> 18:15.817
Und ich sage Ihnen schon mal die einfachste Idee, die einem einfällt.

18:15.837 --> 18:19.443
Die sieht nämlich so aus.

18:19.463 --> 18:21.446
Wir haben hier unseren Speicher.

18:21.506 --> 18:25.632
Und wir haben hier die CPU.

18:25.653 --> 18:28.217
Und die CPU, die spuckt Daten aus.

18:28.277 --> 18:30.460
Und zwar Adressen.

18:33.376 --> 18:52.855
Und jetzt werden wir diese Adressen angucken, ob sie kleiner sind als ein Limit.

18:52.895 --> 18:59.701
Und dann werden wir außerdem noch drauf schlagen.

18:59.721 --> 19:00.362
Ein Offset.

19:04.072 --> 19:05.915
Und was bedeutet das jetzt?

19:05.955 --> 19:16.193
Das bedeutet, wenn wir verschiedene solche Offsets haben, dann können wir unseren Speicher einteilen und uns jetzt sicher sein, dass die CPU nur in diesem Bereich herum geistern kann.

19:17.635 --> 19:20.280
Und das sind zwei Register.

19:20.300 --> 19:23.245
Also die einfachste Speicherverwaltung, und das nennt man dann Segmentierung,

19:29.266 --> 19:30.948
Die braucht nicht mehr als zwei Register.

19:32.430 --> 19:40.580
Mit dem einen Register merken wir uns für einen Prozess, sind wir denn kleiner als das Limit, also in diesem Bereich drin.

19:40.620 --> 19:44.585
Und mit dem zweiten haben wir den Bereich abgesteckt.

19:44.605 --> 19:52.334
Und wenn wir jetzt den nächsten Prozess laufen lassen wollen, also ein zweites Programm zur Ausführung bringen, dann setzen wir einfach einen neuen Bereich an.

19:52.374 --> 19:54.817
Mit dem anderen Aufset, einem anderen Limit.

19:54.837 --> 19:56.539
Diese Dinger nennten wir dann Segmenten.

19:56.992 --> 20:07.670
Also das war so der einfachste Weg und jetzt gibt es natürlich noch einen Bereich, den nennen wir hier einfach OS.

20:07.690 --> 20:11.877
Also das Betriebssystem lassen wir auch in so einem Segment laufen.

20:12.979 --> 20:15.844
Das war der erste Gedanke, wie man mehrere Programme gleichzeitig ausführen kann.

20:17.832 --> 20:19.654
Das sieht halt so aus.

20:19.674 --> 20:22.718
Und jetzt ist die Frage liegt es ganz oben, liegt es ganz unten.

20:22.738 --> 20:25.461
Wie viele Adressen haben wir denn überhaupt und so weiter.

20:25.481 --> 20:29.926
Aber jetzt sind wir auf einmal in der Lage, mehrere Prozesse auszuführen.

20:30.266 --> 20:42.680
Und die Frage ist jetzt, wann laden wir denn diese Register neu?

20:42.720 --> 20:44.122
Das ist immer eine gute Frage.

20:44.142 --> 20:46.725
Und wir wissen auch nicht, also, ja,

20:47.887 --> 20:50.970
Wenn wir das so hinkriegen, dann können wir mehrere Prozesse laufen lassen.

20:51.750 --> 20:56.234
Jetzt könnten wir dem Programm sagen, es muss vorher Anforderungen stellen.

20:59.197 --> 21:03.401
Jetzt werden Sie nachdenken und sagen, okay, rekursive Programm ist Stag.

21:03.421 --> 21:08.085
Das Ganze stammt aus einer Zeit, da war Rekursion und Stag noch nicht erfunden.

21:08.105 --> 21:16.392
Also die Programmiersprache Fortran, Fortran steht für Formula Transleder, eine frühe Sprache aus den

21:16.726 --> 21:20.229
59er-Jahren oder so, die hatten noch kein Stack.

21:20.250 --> 21:22.572
Stack ist erst in den 60er-Jahren erfunden worden.

21:22.812 --> 21:26.316
Und damit war es relativ klar, am Anfang zu sagen, wie viel Platz brauchten wir im Programm.

21:27.697 --> 21:30.420
Haben Sie schon mal einen Assembler programmiert?

21:30.440 --> 21:38.788
Okay, dann wissen Sie, da konnten Sie irgendwie Labels hinschreiben und dann konnten Sie an so ein Label ran schreiben, wie viel Platz da jetzt für eine Viabile liegen soll.

21:38.808 --> 21:43.813
Das sind dann globale Viablen, Rekursions-Stacks haben wir noch nicht, also lokale Viablen gibt es noch nicht.

21:44.350 --> 21:54.360
Das heißt, wir können dem Programm ansehen, wie groß ist der Programm Code und wir wissen, wie viele lokal, also statische Variabeln haben wir und es ist eigentlich schon fertig.

21:54.420 --> 22:09.075
Also das ist so ein bisschen die Idee und sie erinnern sich sicherlich auch noch an diese Ablaufkette, wo man also hier irgendwie einen Compiler hatte und dann hatte man in Linker und dann hatte man Loda.

22:10.625 --> 22:13.289
Und dann hat man die letztlichen Programme.

22:13.309 --> 22:19.617
Der Compiler, der nimmt irgendwie einen Punkt C-Datei und macht daraus eine Punkt O-Datei.

22:19.637 --> 22:37.982
Der Linker, der nimmt zusätzlich noch irgendwelche Lip C Punkt A und weitere, also er nimmt irgendwie Bibliotheken dazu und hier entsteht dann irgendwas, das heißt dann, je nach Betriebssystem Punkt X oder einfach nur ausführbare Datei, A Punkt Out zum Beispiel.

22:40.072 --> 22:46.119
Und der Loda nimmt dann dieses Ding hierher und guckt sich die Datei an.

22:46.139 --> 22:48.642
Da gibt es einen Format.

22:48.702 --> 22:56.210
Es gibt beispielsweise das Kopf Format, was für Kamen, Objekt, Fall Format steht.

22:56.230 --> 22:59.154
Und da gibt es an einem Executor immer einen Kopf dran.

22:59.174 --> 23:02.017
Und im Kopf steht drin, wie viel Platz brauchen wir.

23:02.037 --> 23:04.560
So, und jetzt kann der Loda und das sind halt

23:05.468 --> 23:08.132
Gute Frage, ist das eine Betriebssystemkomponente?

23:08.152 --> 23:12.199
Ja, der Loder ist eine sehr linken Betriebssystemkomponente vielleicht.

23:12.219 --> 23:15.304
In der Regel ist das aber abhängig von dem Betriebssystem.

23:15.324 --> 23:24.539
Ist der Compiler eine Betriebssystemkomponente in der Vergangenheit ja, weil man Betriebssysteme nämlich statisch konfiguriert hat und dafür braucht man ein Compiler.

23:24.579 --> 23:32.472
Also, das Ding läuft im User-Mode, im User-Mode, im User-Mode, aber trotzdem sind es alles irgendwie betriebssystemabhängige Komponenten.

23:32.840 --> 23:39.266
Und am Ende haben wir also in dem A.out-Format die Informationen, wie viel Platz brauchen wir in unserem Prozess.

23:39.286 --> 23:40.467
So.

23:40.487 --> 23:42.750
Und jetzt kommt die nächste Frage.

23:42.770 --> 23:47.474
Es ist Prozess 3 gestorben und Prozess 5 kommt... Ach so, 3 ist gestorben, 1 ist gestorben.

23:47.494 --> 23:51.518
Und jetzt kommt Nummer 5 und möchte mehr Platz haben, als die Lücke groß ist.

23:51.558 --> 23:56.183
Was machen wir?

23:56.203 --> 23:57.524
Dorf, oder?

23:57.544 --> 23:59.646
Können wir 5 laufen lassen?

23:59.686 --> 24:01.348
Die coole Antwort ist, ja, können wir.

24:01.368 --> 24:02.509
Wir müssen nämlich nur

24:02.860 --> 24:05.002
das Offset für die anderen justieren.

24:05.023 --> 24:08.687
Alle Adressen sind ja relativ zu diesem Offset.

24:08.947 --> 24:12.291
Das heißt, unser Programmcode ändert sich gar nicht, wenn wir die Dinger hier hin und her schieben.

24:14.053 --> 24:19.039
Wir dürfen sie nur dann nicht schieben, wenn sie gerade benutzt werden, die Segmenter.

24:19.079 --> 24:24.345
Also Segmentierung erlaubt, dass man sozusagen die Bereiche auch justiert.

24:25.372 --> 24:28.818
gibt es zwei Zeiten, wo man es nicht darf.

24:28.838 --> 24:30.060
Erstens, wenn das Programm selber läuft.

24:30.080 --> 24:35.569
Zweitens, wenn IO-Aktivitäten unterwegs sind, die in diesen Bereich wieder Daten reinschreiben wollen.

24:35.649 --> 24:37.412
Also wenn die Geräte da aktiv sind.

24:37.452 --> 24:39.456
Aber man kommt da ein ganzes Stück weit.

24:39.476 --> 24:45.085
Was macht man, trotzdem machen die Programme, also alle Betriebssysteme heute unterstützen nach wie vor Signatierung?

24:45.605 --> 24:51.014
Aber es wird eigentlich nicht mehr benutzt, sondern es wird ein anderes Schema benutzt, d.h. Paging.

24:51.034 --> 24:53.257
Darauf kommen wir bei Gelegenheit auch noch zu sprechen.

24:53.297 --> 24:56.903
Da ist die Idee, dass wir den Speicher in Seiten einteilen, die alle gleich groß sind.

24:56.943 --> 25:01.751
Damit ist dieses, wir suchen nach der passenden Lücke, verschwunden als Problem.

25:01.811 --> 25:05.597
Wir müssen aber den Adressraum in solche Seiten zerteilen.

25:05.618 --> 25:08.522
Wie das genau geht, da brauchen wir ein bisschen mehr harte Unterstützung.

25:08.562 --> 25:10.245
Das besprechen wir kurz vor Weihnachten.

25:12.233 --> 25:15.202
Okay, jetzt haben wir also die Möglichkeit, unseren Speicher aufzuteilen.

25:15.222 --> 25:19.214
Wir haben auch schon verstanden, dass wir die Prozesse gegeneinander ein bisschen isolieren können.

25:19.254 --> 25:21.400
Und jetzt ist die Frage, wie oft schalten wir denn um?

25:22.966 --> 25:30.924
Und das hat man beim letzten mal auch schon kurz angerissen und haben gesagt, na ja, wir könnten eigentlich umschalten, wenn es die Programme wollen.

25:30.944 --> 25:36.035
Das nennt man dann kooperative Scheduling, Betriebssysteme mit einem kooperativen Scheduler.

25:36.055 --> 25:40.184
Das war zum Beispiel das alte MacOS 8.6.

25:40.485 --> 25:42.409
Das lief damals auf dem PowerPC und so.

25:42.845 --> 25:47.349
Oder das war auch Windows 3.1, also Windows 3.11.

25:47.429 --> 26:05.507
Also kooperativ geschedulte Systeme erfordern wenig Arbeit im Betriebssystem Kern, hängen aber davon ab, dass die Programme sich alle halbwegs benutzen, wenn da jemand in der Endloschleife hängt, dann bleibt halt alles stehen, weil der gibt ja niemals die CPU frei.

26:05.527 --> 26:10.472
Auf der anderen Seite sind kooperativ geschedulte Systeme die effizienteste Umsetzung, weil

26:10.942 --> 26:16.072
Jede Unterbrechung, eigentlich ja Overhead ist.

26:16.112 --> 26:19.759
Was machen, was ist die Alternative zu Kooperativ geschedulten?

26:19.779 --> 26:23.927
Das sind Systeme mit Unterbrechung, also preemptiv.

26:23.947 --> 26:27.634
Und da mal ich auch schon mal im Vorgriff ein kleines Bildchen hin.

26:30.280 --> 26:40.278
Da haben wir nämlich, wir reden jetzt von von von Prozessen und meinen Arbeit tatsächlich Prozesse haben wenigstens eines Rät und da drin geht irgendwas.

26:40.298 --> 26:47.351
Und da geht es los, wir initialisieren irgendwas und dann gehen wir in den Zustand, der heißt ready.

26:47.372 --> 26:50.317
Und da sind vielleicht jetzt vieles Rät unterwegs.

26:50.357 --> 26:53.082
Jetzt wählen wir einen aus, den holen wir nach running.

26:54.817 --> 26:57.559
und lassen den auf der CPU laufen.

26:57.599 --> 26:59.281
Wie lange lassen wir den laufen?

26:59.301 --> 27:09.910
Entweder so lange, bis die Zeitscheibe zu Ende ist, und diese Zeitscheibe, die nennt man Quantum, oder, bis er freiwillig aufgeht.

27:09.950 --> 27:12.532
Warum würde ein Prozess freiwillig aufgeben?

27:12.552 --> 27:13.153
Weil er I.O.

27:13.173 --> 27:13.894
macht.

27:13.914 --> 27:20.359
Weil er zum Beispiel auf Daten wartet, und wenn er mit den Daten fertig ist, dann geht er wieder nach Ready.

27:20.399 --> 27:24.823
Das heißt, wir haben, und irgendwann ist er ganz am Ende, dann ist er hier finished.

27:28.060 --> 27:32.406
Das ist der Ablauf bei präventiv geschehenen System.

27:32.426 --> 27:37.654
Wir haben also Programme, die wir starten, die landen als Prozess in Ready.

27:37.674 --> 27:43.382
Dann wird einer ausgewählt und der kommt nach Running, der kriegt die CPU.

27:43.402 --> 27:45.545
Und zwar so lange, bis er entweder I.O.

27:45.585 --> 27:49.490
macht oder bis seine Zeitscheibe zu Ende ist.

27:49.511 --> 27:53.376
Und die Zeitscheibe zu Ende, das ist typisch in

27:55.128 --> 27:57.251
Unix-System nach 10 Millisekunden.

27:57.291 --> 28:01.756
In Windows ist es 23 Millisekunden aus irgendwelchen historischen Gründen.

28:01.776 --> 28:05.481
In Wirklichkeit funktionieren Scheduler heute anders.

28:05.501 --> 28:09.485
Die lassen, die es jetzt nicht mehr so lange laufen, weil das gar nicht nötig.

28:09.505 --> 28:13.150
Die sind nach einer Millisekunde oder weniger immer schon fertig und sind in Weeding.

28:13.170 --> 28:17.355
Das heißt, wenn Sie sich mal von fair share Scheduler gehört haben,

28:17.757 --> 28:23.369
Da versucht man diese Zeitscheibe zu justieren, eine Abhängigkeit von dem Verhalten der Prozesse.

28:23.429 --> 28:27.056
Aber das ist die Art, wie man Speicher verwaltet im einfachsten Fall da oben.

28:27.077 --> 28:30.103
Und das ist die Art, wie man CPU verwaltet im einfachsten Fall.

28:30.123 --> 28:35.935
Und schon sind wir im Prinzip soweit, dass wir mehrere Programme laufen lassen können, mehrere Prozesse.

28:37.467 --> 28:50.852
Man nennt das Ganze dann CPU Scheduling und beim Scheduling, da werden wir auch noch dediziert drauf eingehen, gibt es halt einen langen Zeit Scheduler, also ein Scheduler heißt auf Deutsch Farbland.

28:51.187 --> 28:53.589
Also wir machen einen Fahrplan, wie bei Eisenbahn.

28:53.609 --> 28:55.751
Und dann gibt es ja noch den Dispatcher.

28:55.771 --> 29:00.315
Das ist der, der auf Rotkäppchen auf dem Bahnsteig die Sache abfahren.

29:00.335 --> 29:02.557
Und das gibt es beim Betriebssystem auch.

29:02.577 --> 29:05.760
Wir wählen halt Prozesse aus.

29:05.780 --> 29:08.863
Wir lassen Prozesse überhaupt erst zu.

29:08.883 --> 29:12.146
Und dafür haben wir viel Zeit.

29:12.166 --> 29:15.929
Also der Scheduler selber kann sich eigentlich relativ viel Zeit nehmen.

29:15.969 --> 29:18.932
Aber der Dispatcher, der die Umschaltung macht, der muss schnell sein.

29:19.553 --> 29:21.195
Weil der kommt alle naselang dran.

29:21.215 --> 29:26.840
Also alle 10 Millisekunden zum Beispiel.

29:26.900 --> 29:27.580
Genau.

29:27.600 --> 29:30.343
Jetzt nochmal zum Merken.

29:30.383 --> 29:33.346
Ein Programm ist passiv, ein Prozess ist aktiv.

29:33.366 --> 29:36.869
Kann das das gleiche Programm mehrfach geben auf dem Computer?

29:36.889 --> 29:38.991
Ja, kann es schon, ist aber eigentlich ungewöhnlich.

29:39.011 --> 29:43.896
Kann es Prozess, also wie viele Prozesse können existieren zu einem Programm?

29:43.916 --> 29:44.957
Ja, kommt darauf an.

29:44.977 --> 29:48.700
Also ich kann das gleiche Programm mehrfach starten, dann habe ich halt viele Prozesse.

29:50.283 --> 29:52.306
Ein Prozess ist ein Ressourcencontainer.

29:52.346 --> 29:54.909
Das heißt, CPU und Speicher haben wir gerade besprochen.

29:54.950 --> 29:56.952
Wie IO geht, haben wir nicht besprochen.

29:56.992 --> 29:59.656
Es betrifft sich mit zwei Themen.

29:59.696 --> 30:16.780
Im Prinzip ist die Idee, dass wir sagen, wir haben einen Handel, einen File-Descriptor, also wir haben ein Referenz auf die Ressourcen, die wir für IO benutzen wollen.

30:17.350 --> 30:19.653
Gucken wir uns auch noch an, was ist eigentlich ein Datei?

30:19.673 --> 30:22.276
Wir nehmen an, heute ist eine Folge von Bytes.

30:22.296 --> 30:26.581
Gibt aber viel komplexere Dateisysteme.

30:26.621 --> 30:34.910
Wenn wir sagen, wir haben eine Folge von Bytes und das ist jetzt unsere Datei, dann müssen wir uns wenigstens merken, den Lese- und Schreibzeiger.

30:36.051 --> 30:47.104
Weil wenn wir das nächste Mal GEPK sagen, aber GEPC, dann wird der an dieser Stelle uns das nächste Zeichen besorgen.

30:47.607 --> 30:55.875
Und wenn Sie Datei öffnen mit Open.

30:55.895 --> 31:00.019
Was nimmt Open für Argumente?

31:00.039 --> 31:05.825
Habe ich vor Programm geschrieben, was Dateien kopiert?

31:05.845 --> 31:10.449
Ein Name, ne?

31:10.469 --> 31:17.416
Nehmt noch mehr Argumente?

31:17.436 --> 31:17.496
Ja?

31:20.834 --> 31:25.621
Genau, geht weit, ne?

31:25.641 --> 31:31.870
Und das ist deshalb wichtig, weil, wenn Sie eine Datei zum Lesen öffnen, dann wird der Leseschreibzeiger hier positioniert.

31:31.890 --> 31:35.295
Wenn Sie die aber zum Schreiben öffnen, dann wird der hier hinten positioniert.

31:35.315 --> 31:42.446
So, dass weitere Schreiboperationen die Datei verlängern und weitere Leseoperationen dafür sorgen, dass von vorne gelesen wird.

31:42.506 --> 31:47.854
Also, das Betriebssystem muss beim Zugriff auf Dateien so ein Leseschreibzeiger verwalten.

31:48.475 --> 31:55.564
Und Windows legt dafür ein File-Objekt an für jede Datei, für jede einmal geöffnet Datei.

31:55.584 --> 32:02.852
Unix hat ähnliche Abstraktionen, die halten damit.

32:02.932 --> 32:04.715
Ja, genau.

32:04.755 --> 32:10.922
Wenn der Prozess fertig ist, dann müssen wir die ganzen Ressourcen, die er verbraucht hat, wieder freigeben.

32:11.442 --> 32:13.694
Und das Betriebssystem muss die alle wieder einsammeln.

32:13.734 --> 32:16.709
Das klappt meistens, manchmal klappt es nicht so gut.

32:16.729 --> 32:19.242
Haben Sie schon mal von Interprozess-Kommunikationen gehört?

32:21.770 --> 32:37.327
Wenn Sie hier IPCs hinschrücken, dann sehen Sie auf einmal unser Knochen hier, das ist POSIX in der Prozesskommunikation, der hat sogar eine Message Queues und Shared Memory uns immer vor.

32:37.387 --> 32:45.155
Das sind Datenstrukturen, die für die Kommunikation zwischen verschiedenen Prozessen verwendet werden.

32:45.196 --> 32:50.241
Und das Betriebssystem weiß nicht, wanns die wieder freigeben kann oder soll.

32:54.507 --> 32:57.490
System 5 in der Process Communication Facility.

32:57.550 --> 33:02.915
Und jetzt haben wir bloß mal geguckt und haben gesehen, auf dem Rechner hier ist alles in Ordnung.

33:02.955 --> 33:07.000
Da sind gerade keine Shared Memory-Segmente zum Beispiel belegt.

33:07.040 --> 33:22.455
Aber wenn Sie anfangen zu programmieren und sagen, ich habe jetzt zwei Prozesse, zwei, die miteinander reden und die müssen solche Shared Memory-Segmente verwalten, dann weiß das Betriebssystem nicht, wann die wieder freigegeben werden können.

33:23.026 --> 33:31.095
Bei den meisten Ressourcen ist es so, Programm wird gestartet, Prozess wird erzeugt, Ressourcen werden angefordert, Fileskriptoren.

33:31.155 --> 33:36.541
Und wenn Sie das Programm beenden, werden alle Fileskriptoren geschlossen, alle Puffer geflasht und dann ist wieder aufgeräumt.

33:38.222 --> 33:45.150
Es gibt aber einen Spezialfall und das waren hier diese Shared Memory-Segmente, Message Cues und Semaphore.

33:45.170 --> 33:47.833
Da weiß das Betriebssystem nicht, wann es aufräumen soll.

33:47.873 --> 33:50.856
Und da muss unter Umständen der Mensch noch mal ran.

33:53.165 --> 33:59.377
Wir merken uns, bei der Terminierung von Prozessen wird das Betriebssystem alle Ressourcen wieder freigeben.

34:00.860 --> 34:07.293
Im Prozess hat Meeresrez und jeder hat einen eigenen Programm counter.

34:07.353 --> 34:14.667
Also auch wieder GDS, die erinnern sich, gab es den Satz von Registern, General Purpose Register, Gleitkommaregister und ein paar Ausgewiesene.

34:14.950 --> 34:23.863
gab es das Instruktionsregister, den Programmscounter, StackPointer und wenigstens Programmscounter, StackPointer muss jedes Rett separat haben.

34:27.927 --> 34:40.063
Prozessmanagement, was steckt dahinter, das Erzeugen und Löschen von Prozessen, sowohl für gewöhnliche Anwendungen als auch für System, Suspending und Resuming von Prozessen.

34:40.083 --> 34:46.853
Man kann Programme also nicht terminieren, sondern einfach vom Scheduling ausschließen.

34:46.873 --> 34:54.643
Wenn Sie sagen, der geht hier nach Weht und da bleibt er auch, dann haben Sie das Programm zwar noch auf der Maschine, der Speicher ist noch belegt,

34:54.944 --> 34:57.428
Aber das kriegt jetzt keine CPU mehr ab.

34:57.468 --> 35:00.473
Warum will man so was machen?

35:00.493 --> 35:03.317
Es gibt so ein Phänomen, das heißt Trashing.

35:03.357 --> 35:12.131
Wenn, also sagen wir mal, der Speicher knapp ist auf unserem Computer, dann wird folgendes passieren, ein Programm fängt an zu laufen, stellt fest, droppler.

35:12.151 --> 35:15.776
Meine Daten sind gar nicht im Hauptspeichel, sind ausgelagert auf dem Sekundärspeicher.

35:15.796 --> 35:17.359
Ich muss die erst mal reinholen.

35:17.399 --> 35:19.021
Sie rein geholt.

35:19.061 --> 35:22.707
Wenn er damit fertig ist, ist die Zeitscheibe vorbei und der muss wieder aufgeben.

35:22.957 --> 35:25.020
Kommt nächste Programm dran, nächster Prozess.

35:25.060 --> 35:26.723
Hoppla, meine Daten sind alle ausgelagert.

35:26.743 --> 35:28.726
Ich muss erst wieder einlagern.

35:28.746 --> 35:30.689
Zeitscheibe vorbei und so weiter.

35:30.709 --> 35:38.521
Also es gibt so ein Phänomen, dass ein Betriebssystem sich im Wesentlichen mit sich selber beschäftigt, wenn zu viele lauffähige Prozesse vorhanden sind.

35:38.601 --> 35:41.826
Und das kann man mit Suspender-Sume halt ein bisschen steuern.

35:44.017 --> 35:47.444
Was wir auch noch machen müssen, ist Sinkronisation und Kommunikation zwischen Prozessen.

35:47.464 --> 35:49.448
Da hatte ich Ihnen gerade schon ein Beispiel gezeigt.

35:49.468 --> 35:54.077
Und dann gibt es noch diese Deadlock-Behandlung.

35:54.097 --> 35:55.079
Also Verklemmung.

35:55.099 --> 36:01.451
Wenn Prozesse sich miteinander verklemmen, weil der eine produziert, also beide möchten auf... Was ist eine Verklemmung?

36:01.471 --> 36:02.413
Wie kann es hier passieren?

36:11.573 --> 36:14.357
Wir schreiben ein Programm mit zwei Sreds, ja?

36:14.377 --> 36:16.479
Es wird 0 und es wird 1.

36:16.539 --> 36:20.704
Und hier haben wir irgendwie Dada.

36:20.725 --> 36:22.447
Und das soll jetzt ein Konto sein, ne?

36:22.467 --> 36:33.280
Und der hier, der macht, wie heißt es, wenn man was aufs Konto rauf zahlt, einzahlen.

36:33.300 --> 36:39.328
Abheben heißt WisDraw, ne?

36:39.368 --> 36:40.990
Und das hier heißt Deposit, glaube ich, ne?

36:44.615 --> 36:49.640
Und jetzt wollen wir machen die Prosit von ... von zehn.

36:49.660 --> 36:52.222
Wollen Sie sich übertreiben?

36:52.242 --> 36:57.828
Und der hier will auch ein Vistor machen von fünf.

36:57.848 --> 36:58.749
Ah, von zehn.

36:58.769 --> 37:05.856
Wir heben es auch wieder ab.

37:05.876 --> 37:08.418
Ach so, und der da ist vielleicht ein Account, ne?

37:08.458 --> 37:12.462
Und wir machen am Anfang mal da da gleich null.

37:14.045 --> 37:16.609
wird es initialisiert.

37:16.709 --> 37:34.718
Und jetzt ist die Frage, wie würden wir denn hier deposit implementieren?

37:34.738 --> 37:34.918
So, oder?

37:34.938 --> 37:36.120
Und der hier, der macht

37:46.647 --> 37:48.690
Wie viele Instruktion haben wir da jetzt gerade hingeschrieben?

37:50.132 --> 37:54.418
Das ist C, in C können Sie so eine Zuweisung machen.

37:54.438 --> 38:02.209
Also Sie nehmen sich die Variable, den alten Wert, rechnen drauf rum und weisen ihn gleich wieder auf die Variable zu.

38:02.249 --> 38:07.616
Wie viele Instruktionen stecken dahinter?

38:07.656 --> 38:15.507
Dahinter steckt, das wir sagen, wir haben ein Register, sagen wir mal R. R ist gleich da da.

38:17.545 --> 38:27.116
Dann machen wir einen Inkrement.

38:27.136 --> 38:36.106
Und dann machen wir da, da ist gleich A.

38:36.227 --> 38:37.969
Also es passiert in drei Schritten.

38:38.009 --> 38:40.131
Und hier passiert natürlich dasselbe.

38:40.271 --> 38:44.396
R ist gleich D da.

38:44.456 --> 38:45.257
Dekrement.

38:47.684 --> 38:51.089
Ja, und zehn.

38:51.109 --> 38:58.801
Und dann sagen wir, er soll ein Register sein.

38:58.841 --> 39:07.094
Und es ist jetzt bloß eine Andeutung, dass Prozessoren heutzutage auf Registern rechnen und nicht etwa am Hauptspeicher.

39:07.114 --> 39:11.641
Jetzt ist die spannende Frage, welchen Wert haben wir in DEDA am Ende der Ausführung?

39:11.661 --> 39:12.122
Vorschläge.

39:18.430 --> 39:22.636
Wer ist für 0?

39:22.696 --> 39:25.620
Okay, also 0.

39:25.640 --> 39:32.871
Weitere Vorschläge.

39:32.891 --> 39:40.181
Ist jemand für 10?

39:40.201 --> 39:40.261
Ja?

39:40.281 --> 39:42.384
Und was noch?

39:42.404 --> 39:42.885
Genau.

39:49.801 --> 39:52.564
Wie kann es passieren?

39:52.584 --> 39:54.226
Wir haben ja unsere CPU, ne?

39:54.246 --> 39:58.291
Hier.

39:58.311 --> 40:01.474
Und die führt den SRED 0 aus und den SRED 1.

40:01.494 --> 40:03.837
Wir haben nur eine CPU.

40:03.877 --> 40:06.099
Wenn wir zwei haben, wird es noch schlimmer.

40:06.139 --> 40:10.704
Aber jetzt wird ja umgeschaltet, ne?

40:10.744 --> 40:15.690
Wir hatten gesagt, es gibt Priemption-Unterbrechen, die das Bild da oben ist jetzt gerade verdeckt.

40:17.982 --> 40:23.527
Hier, die Frage ist, wann diese Unterbrechung stattfindet.

40:23.547 --> 40:34.977
Also es könnte ja so sein, dass der hier läuft und dann läuft der und dann kommt raus null, ganz klar.

40:37.319 --> 40:46.447
Aber es könnte ja auch passieren, dass der hier läuft, bis hierhin, dann wird er unterbrochen, dann läuft der.

40:46.467 --> 40:47.668
Da hat er also jetzt gelesen,

40:48.273 --> 40:54.698
0 plus 10 kommt aber nicht dazu, die 10 zurückzuschreiben.

40:54.859 --> 41:04.266
Der Kumpel hat in der Zwischenzeit seine minus 10 eingetragen, aber dann kommt der hier nochmal zum Zug und wird es überschreiben.

41:04.286 --> 41:07.129
Da steht auf einmal plus 10 drin.

41:07.169 --> 41:18.178
Das Ganze geht natürlich andersrum auch, dass der hier erst minus 10 ausrechnet, die nicht zurück schreibt, dann rechnet der seinen Spielchen zu Ende und dann kommt am Ende eine minus 10 raus.

41:20.335 --> 41:36.744
Wenn man sowas vermeiden möchte, braucht man kritische Abschnitte.

41:36.764 --> 41:43.997
Wir haben hier einen kritischen Abschnitt und man braucht einen Feature, das heißt gegenseitiger Ausschluss.

41:51.638 --> 41:54.421
oder auf Englisch Mutual Exclusion.

41:58.766 --> 42:02.390
Und das nennt man ganz allgemein Synchronisation.

42:02.590 --> 42:06.455
Wir müssen die beiden zerts gegeneinander synchronisieren.

42:06.475 --> 42:20.110
Und es gibt eine ganze Theorie, das gucken wir uns in Kapitel 3 an, wie man sich mit dieser Nebenläufigkeit auseinandersetzt und wie man Aktivitäten gegeneinander synchronisiert, also wie man solche kritischen Abschiede baut.

42:21.220 --> 42:23.363
waren Sie schon mal in Schweden?

42:23.383 --> 42:25.106
War ich immer schon mal in Schweden?

42:25.126 --> 42:26.708
In einem Laden dort?

42:26.728 --> 42:33.698
Wenn Sie in Schweden in den Laden gehen, dann ist es nicht so, dass man in einer Wartelschlange stehen muss, wie in Deutschland, sondern dann nehmen Sie sich alle ein Ticket.

42:33.718 --> 42:40.247
Und dann kriegt man, irgendwann werden die Leute ein Ticket entsprechend abgearbeitet.

42:40.508 --> 42:43.532
Man kann sich irgendwie in die Ecke setzen und warten.

42:45.098 --> 42:46.221
Das ist ein cooles Konzept.

42:46.241 --> 42:51.174
Die Frage ist, wie sorgt man dafür, dass jeder ein verschiedenes Ticket hat?

42:51.214 --> 42:54.783
Also er hat eins, der nächste hat zwei, der nächste hat drei.

42:54.803 --> 43:01.099
Und da könnte man sagen, das Problem kann man lösen, wenn man den gegenseitigen Ausschluss schon gelöst hat.

43:01.720 --> 43:09.929
Wenn man ihn noch nicht gelöst hat, dann kann man wenigstens dafür sorgen, dass die Folge der Tickets Monotone nicht fallend ist.

43:09.949 --> 43:17.097
Also es kann sein, es gibt drei, die kriegen Ticket eins, dann gibt einer mit Ticket zwei, dann kommen wieder zwei mit Ticket drei, dann kommen wieder ... Ja?

43:17.117 --> 43:19.960
Aber damit haben wir das Problem schon zur Hälfte gelöst.

43:20.001 --> 43:23.044
Weil wir haben jetzt also eine Folge von Tickets.

43:23.064 --> 43:28.470
Und wenn zwei das gleiche Ticket haben, dann sagen wir, es ist der dran, der die kleinere Prozess-ID hat.

43:29.412 --> 43:34.678
Die Prozess-ID, die geben wir beim Start der Prozesse raus.

43:34.698 --> 43:42.046
Diesen Algorithmus, den nennt man Big-Ri Algorithmus, das ist eine Software-Lösung, um diesen gegenseitigen Ausschluss zu implementieren.

43:42.086 --> 43:44.469
Das war tatsächlich ein erster Versuch.

43:44.529 --> 43:48.133
Und die Papers dazu, die sind so aus den 60er Jahren.

43:48.173 --> 43:57.103
Also das ist, Computer aufhunden, war 1943, die Synchronisation richtig gelöst, hatte man in den 60er Jahren.

43:57.123 --> 43:58.525
Also es war ein schwieriges Ding.

43:59.365 --> 44:13.122
Und die einfache Lösung oder die finale Lösung, die sieht nochmal anders aus, die sieht nämlich so aus, dass man in die Befehlssätze der Prozessoren eine Test- und Set-Anweisung eingebaut hat, ja?

44:13.142 --> 44:15.765
Oder Compaire, Swap oder Exchange, so heißt die.

44:15.785 --> 44:22.513
Also eine Anweisung, die Atomar, ohne zu unterbrechen, lesen und schreiben gleichzeitig kann.

44:24.135 --> 44:26.218
Das unterstützen heute alle Prozessoren.

44:26.238 --> 44:28.140
Betriebssystem hängt davon ganz gewaltig ab.

44:28.373 --> 44:33.005
Es ist ein Beispiel wie Software und Hardware sich gegenseitig beeinflussen.

44:34.048 --> 44:37.818
Das haben Sie alle schon gehört bei GDS, oder?

44:37.838 --> 44:40.525
Testenset.

44:40.545 --> 44:43.092
Ich weiß immer, immer nein sagen ist schon die Richter einfach.

44:45.755 --> 44:46.576
Genau.

44:46.596 --> 44:50.103
Jetzt haben wir also über Prozessverwaltung ganz kurz gesprochen.

44:50.143 --> 44:52.246
Wir haben über das Thema Gegenseit der Ausschluss gesprochen.

44:52.286 --> 44:55.171
Wir haben gesagt, wir müssen irgendwie für Synchronisation sorgen können.

44:55.191 --> 44:59.519
Wir haben über Speicherverwaltung auch schon ein bisschen was gesagt.

44:59.539 --> 45:04.528
Und ich hatte Ihnen Segmentierung erzählt, was Swapping ist und was Würtellerspeichern.

45:04.548 --> 45:05.890
Jetzt haben wir noch nicht gesagt.

45:05.870 --> 45:18.951
Also Swapping ist zunächst eine Idee, dass man sagt, dieses Speichersegment, was zu einem Prozess jetzt gehört, das lagen wir komplett aus, das legen wir auf die Platte.

45:18.971 --> 45:21.055
Und dafür holen wir ein anderes rein.

45:21.075 --> 45:23.759
Auch die Weise können wir zwischen zwei Prozessen umschalten.

45:23.799 --> 45:32.113
Auch wenn der Speicher unseres Rechners eigentlich nicht sehr groß ist, legen wir halt den einen auf Eis und holen den anderen rein und dann lassen wir ihn eine Weile rechnen.

45:33.916 --> 45:36.902
Wer hat schon mal von fork und exec gehört?

45:36.922 --> 45:39.487
Das sind die Unix System aufrufe um Prozesse zu erzeugen.

45:42.513 --> 45:43.876
Das kommt aus der Zeit.

45:43.896 --> 45:47.904
Mit fork erzeugt man ein Abbild des laufenden Prozesses auf Deutsch.

45:47.924 --> 45:51.752
Wir legen den laufenden Prozess auf die Platte.

45:51.792 --> 45:54.878
Und mit exec laden war in den laufenden Prozess ein neues Programm rein.

45:55.853 --> 46:04.045
So tickt Unix in Windows, in VMS, da sagt man createProcess, da ist es in einem System auch hoch zusammengefasst, da geht es anders.

46:04.085 --> 46:12.256
Aber, erste Idee war jedenfalls, wenn wir nicht genug Speicher haben, dann lagern wir ganze Prozesse auf die Festplatte aus.

46:12.296 --> 46:14.419
Die nächste Idee war dann, dass wir den Speicher virtualisieren.

46:14.459 --> 46:20.528
Das war also sagen, ja, der Prozess kann Speicher verwalten und benutzen und scheinbar hat er auch endlos viel.

46:20.980 --> 46:25.898
Aber in Wirklichkeit ist nur ein kleiner Teil davon tatsächlich im Hauptsprecher Präsent.

46:25.918 --> 46:27.785
Der Rest ist auf die Platte ausgelagert.

46:27.825 --> 46:30.776
Dieser Teil, der im Hauptsprecher Präsent ist, den nennt man Working Set.

46:30.796 --> 46:32.121
Gucken wir uns auch noch an, wie es geht.

46:34.582 --> 46:38.128
Dateisystem, da hatte ich Ihnen schon so einen kleinen Vorgeschmack gegeben.

46:38.148 --> 46:42.875
Lesen Schreibzeiger, das ist ein Datei.

46:42.915 --> 46:47.122
Jetzt haben andere Betriebssysteme da noch viel coolere Ideen.

46:47.162 --> 46:55.155
Also beispielsweise könnten wir uns ja sagen, wenn wir das Telefonbuch implementieren wollen, dann könnten wir sagen, die Einträge sind alle gleich groß.

46:56.232 --> 47:01.021
Weil es immer ein Vornamen, Nachname, maximal, weiß ich nicht, 24 Buchstaben.

47:01.041 --> 47:05.449
Und dann haben wir noch eine Telefonnummer, die hat von mir aus 10 Ziffern fertig.

47:05.509 --> 47:12.182
Und jetzt baue ich einen Record strukturiertes Dateisystem, wo ich viel schneller zu einzelnen Records springen kann.

47:12.854 --> 47:16.959
Und jetzt kann man noch eins draufsetzen.

47:16.979 --> 47:18.040
Das heißt dann fausam.

47:18.060 --> 47:21.444
Virtual Storage Access Method hat die IBM im Mainframe gemacht.

47:21.464 --> 47:27.031
Wenn ich erst mal so eine Records habe, dann baue ich vorne einfach einen Index ran.

47:27.051 --> 47:28.372
Und dann habe ich eine Datenbank.

47:28.392 --> 47:30.635
Also ein Dateisystem kann durchaus auch eine Datenbank sein.

47:32.097 --> 47:35.621
Also da gibt es viele Spielrichtungen oder viele Geschmacksrichtungen.

47:35.641 --> 47:41.848
Was wir als sozusagen kleinsten gemeinsam Nenner heute annehmen, ist eine Datei ist eine Folge von Bytes.

47:43.229 --> 47:52.261
Wir werden sehen, dass Windows an der Stelle ein bisschen cooler ist als Linux, weil in Windows ist eine Folge von Attribut-Wertpaarin und ich kann also mehrere Datenströme haben in einer Datei.

47:54.083 --> 47:56.507
Warum will ich das machen?

47:56.547 --> 48:06.660
Ja, das war eine Erfindung eigentlich vom Mac, dass man nämlich auf eine Datei klickt und da geht ein Programm an, was die Datei bearbeitet.

48:06.700 --> 48:08.022
Das sind Sie heute alle gewohnt, oder?

48:08.170 --> 48:14.340
In unserem Explorer oder Finder oder keine Ahnung, wie es gerade heißt, klicken Sie drauf und dann geht das richtige Programm an.

48:14.360 --> 48:26.679
Woher weiß das Betriebssystem eigentlich, was das richtige Programm ist?

48:26.779 --> 48:29.743
Naja, was man heute, also heute gibt es zwei Ideen.

48:29.883 --> 48:31.306
Es gibt eigentlich drei Ideen.

48:31.346 --> 48:32.828
Eine Idee ist,

48:32.960 --> 48:36.885
Wir gucken uns die Endung an und an dem Dateinamen lesen was ab.

48:36.905 --> 48:39.429
Es ist natürlich doof, wenn die Leute sich Dateien falsch benennen.

48:39.449 --> 48:41.031
Dann geht es nicht mehr.

48:41.071 --> 48:45.437
Die zweite Idee, das ist EDC Magic.

48:45.457 --> 48:48.982
Also in UNIX war es lange Zeit üblich, dass man gesagt hat, wir gucken uns den Kopf der Dateien.

48:49.002 --> 48:52.087
Den Kopf müssen wir sowieso angucken wegen Loder.

48:52.127 --> 48:54.630
Und aus dem Kopf leiden wir einfach ab, was es ist.

48:55.640 --> 48:59.905
Also, ob es ein Text-Dokument ist oder ob es ein ausführbare Datei ist und so weiter.

48:59.925 --> 49:09.816
Und die dritte Idee, und das ist die eigentlich saubere, das hat der Mac gemacht, der hat gesagt, wir speichen in der Datei einfach, welches Programm zur Verarbeitung benutzt wird.

49:09.856 --> 49:15.323
Und zwar nicht als Datenstrom, sondern in einem separaten Datenstrom, der sogenannte Resource Fork.

49:17.325 --> 49:22.491
Und Microsoft hat irgendwann hier Windows Services für Mac implementiert und hat bei der Gelegenheit,

49:22.758 --> 49:25.401
weitere Datenströme, ResourceForks implementiert.

49:25.441 --> 49:29.025
Und die haben nicht aufgehört mit einem, sondern man kann viele Datenströme haben.

49:29.085 --> 49:36.192
Das heißt, ich kann in der Datei, nicht nur einmal, sondern viele male Datenspeichern.

49:36.212 --> 49:37.213
Warum ist das interessant?

49:37.874 --> 49:44.581
Stellen Sie sich vor, Sie haben einen richtig großen Server und Sie haben nicht mehr alle Dateien online, sondern manche auf dem Bandroboter ausgelagert.

49:44.601 --> 49:49.306
Das heißt dann Hierarchical Storage Management oder hierarchische Speicherverwaltung.

49:49.346 --> 49:51.769
Da lässt man die Datei einfach bestehen, macht aber die Größe auf Null.

49:52.458 --> 50:00.130
und schreibt, also den ganzen Inhalt löscht man auf Deutsch, und schreibt in den zweiten Datenstrom rein, wo der Inhalt heute zu finden ist.

50:00.151 --> 50:02.915
Nämlich irgendwo im Band.

50:03.195 --> 50:14.394
Und wenn man jetzt auf die Datei zugreifen will, dann kann man transparent für den Nutzer nicht sichtbar das Band anschmeißen, die Daten zurückkohlen, Datei wieder herstellen und ihn dann zugreifen lassen.

50:14.414 --> 50:18.921
Das ist eine Verwendung von diesen Datenströmen.

50:19.880 --> 50:23.664
Wir merken uns, Dateien sind Folgen von Bytes.

50:23.684 --> 50:27.389
Das ist kleinste gemeinsame Nenner, klappt in jedem Betriebssystem.

50:27.409 --> 50:29.151
Manchmal können die Systeme mehr.

50:29.211 --> 50:33.235
Was ist jetzt ein Directory?

50:33.255 --> 50:35.017
Naja, wir haben nicht so viele Ideen, ne?

50:35.037 --> 50:40.324
Also, Directory ist ein Datei mit einem festen Format.

50:40.344 --> 50:43.207
Haben Sie schon mal von 8.3 Format gehört?

50:43.307 --> 50:48.553
MSTOS-Namen, 8 Byte für Namen, ein Punkt, drei Namen für die Endung, ja?

50:49.900 --> 50:52.302
Das war so eine Idee, ne?

50:52.322 --> 50:55.265
Frühe Junixte, die hatten 14 Beit für den Dateinamen.

50:55.305 --> 51:00.330
Also nicht plus 12, sondern 14.

51:00.350 --> 51:00.451
Cool.

51:00.471 --> 51:06.396
Und eine Direktorie ist einfach eine Folge von Namen der enthaltenen Dateien.

51:06.456 --> 51:11.842
Und zusätzlich speichert man noch einen Verweis auf den Dateinhalt.

51:11.862 --> 51:16.026
Im sogenannten Ein-Node oder Information-Node.

51:16.495 --> 51:24.205
Diese Idee, dass also Direktoris einfach nur spezielle Dateien sind, die finden wir heute auch in allen Betriebssystemen.

51:27.470 --> 51:39.365
Viele Vorteile lassen sich nämlich leicht implementieren, hat an einer Stelle Nachteil, wenn sie ein Direktori anlegen und in dem Direktori ganz viele Dateien abkippen, dann wird dies Direktori groß.

51:39.426 --> 51:42.790
Wenn sich Dateien jetzt alle wieder löschen, dann wird es nicht wieder klein.

51:44.137 --> 51:52.596
Also wenn Sie mal zu Hause in Ihr Linux gucken und das Temp-File-System angucken oder EDC angucken, wie groß sind denn diese Verzeichnisse?

51:52.616 --> 51:58.770
Dann sind die aus irgendwelchen Gründen, weil da mal Software installiert wurde und viele temporäre Dateien erzeugt worden sind, sehr groß.

51:59.662 --> 52:02.967
Also sehr groß heißt ein paar K, ein paar Kilowatt.

52:02.987 --> 52:04.369
Das ist schon noch überschaubar.

52:04.409 --> 52:06.672
Aber das ist halt der einzige Nachteil.

52:06.692 --> 52:13.422
Und jetzt können wir als Betriebssystem Dateien und Verzeichnisse erzeugen, manipulieren und so weiter.

52:13.442 --> 52:20.372
Noch mal so ein Stichwort von wegen, was cooles geht, wenn Sie sich das Thema Versionierung angucken.

52:20.392 --> 52:22.715
Ja, jeder hat schon mal ausversehen und was gelöscht.

52:22.755 --> 52:24.117
Und wer schön ist, ist noch da.

52:24.890 --> 52:31.376
In dem VMS-Betriebssystem, da hatte eine Datei nicht bloß einen Namen und eine Endung, sondern auch noch eine Versionsnummer.

52:31.416 --> 52:41.545
Und wenn Sie eine Datei sozusagen bearbeitet haben mit einem Editor, wie i, dann wurde hinterher eine neue Version der Datei angelegt.

52:41.585 --> 52:43.887
Die alte blieb da.

52:43.927 --> 52:48.611
Also quasi Git, kurz dann ins Dateisystem eingebaut.

52:48.731 --> 52:52.855
Da fragt man sich, wie konnte sowas vergessen werden?

52:53.341 --> 52:58.441
Also vms bloß mal so für die Erinnerung ist aus den 1970er Jahren.

52:58.462 --> 53:03.823
Also Dateisystem kann viel mehr als nur flache Dateien, aber das ist das Minimum.

53:06.098 --> 53:24.382
Genau, und dann haben wir die Verwaltung von Massenspeicher, also von Festplatten oder von SSDs, und zwar nicht von 1 und 2, sondern von vielen, also Tausende zum Beispiel, wenn Sie sich einen großen Server angucken, da muss ein Betriebssystem auch können.

53:24.402 --> 53:35.076
Da gibt es Operationen, wie das montieren und das wieder entfernen, die Verwaltung des leeren Speichers, nicht die Allokation von Speicher, die Verwaltung der Platten.

53:36.811 --> 53:38.913
Sie kennen alles Moos Law.

53:38.933 --> 53:42.077
Zahl der Transistoren verdoppelt sich alle 18 Monate.

53:42.097 --> 53:46.101
Das führt zu einem immensen Gewinn an Performance in der CPU.

53:46.121 --> 53:49.504
Das Speichersystem hat nicht ansatzweise mitgehalten.

53:49.544 --> 53:52.828
Speichersystem ist im Wesentlichen nicht schneller geworden.

53:52.868 --> 54:02.498
Und man kann sich merken zwischen CPU und Hauptspeicher und Hauptspeicher und Sekundärspeicher ist immer ein Faktor 1000 in der Zukunftszeit.

54:02.984 --> 54:09.236
Also wenn sie Daten erst von der Platte holen müssen, dann haben sie so richtig verloren in ihrem Programm.

54:09.276 --> 54:11.680
Betriebete Themen machen dann Tricks.

54:11.700 --> 54:19.575
Also beispielsweise, wir hatten hier gesagt, gibt es Bibliotheken, die von allen Programmen benutzt werden.

54:20.332 --> 54:23.196
Bei Windows gibt es in der Registrierungsdatenbank ein Eintracht.

54:23.216 --> 54:28.383
Das sind die Well-Know-DLLs, also die gut bekannten dynamischen Bibliotheken.

54:28.403 --> 54:31.007
Die LEDs betrifft das System einfach mal beim Start.

54:31.027 --> 54:35.674
Sicherheitshalber, weil die werden bestimmt benutzt und damit werden Programme viel schneller starten.

54:36.695 --> 54:40.020
Wir werden uns bei Thema Speicherverwaltung angucken.

54:40.040 --> 54:42.043
Da gibt es sogenannte Soft- und Hard-Page-Forwards.

54:42.063 --> 54:48.752
Also ein Page-Forward bedeutet, ich hole Daten von der Platte rein, ein Soft-Page-Forward, ich hole mir die in Adressraum, die sind aber schon im Speicher vorhanden.

54:49.002 --> 54:51.085
Soft-Page-Folks gehen viel schneller.

54:51.105 --> 55:00.997
Also, zu Storage Management gehört auch, das war dafür Sorgen, dass Sachen möglichst schnell und rechtzeitig im Hauptspeicher sind.

55:01.017 --> 55:03.260
Stichwort, read the head.

55:03.280 --> 55:12.191
Und dazu gehört auch, dass wir Dinge so auf die Platten verteilen, weil der einzige Weg, die Dinger schneller zu kriegen ist, das zu verschränken.

55:12.211 --> 55:16.697
Und zu sagen, jeder einzelne Platte ist langsam, aber, wenn ich 1000 Stück habe,

55:16.677 --> 55:22.807
Dann kann ich ja 1.000 Operationen auf diesen Platten gleichzeitig ausführen und dann ist im Schnitt jede Operation wieder schneller.

55:24.930 --> 55:34.566
Das ist im Grund, warum sie in großem Storage-System kleine Platten haben, die dann irgendwie 2 Gigabyte groß sind oder so, weil man davon sehr viele haben möchte.

55:35.788 --> 55:38.753
Partitionierung und Schutz der Platten ist dann auch nochmal so ein Thema.

55:40.370 --> 55:47.739
IO-Subsystem, da müssen wir die Spezifika der Hardware vor dem Nutzer verbergen.

55:47.759 --> 55:51.283
Nicht kein Mensch will wissen, wie man ein PCI-Gerät richtig bedient.

55:51.303 --> 55:53.726
Das soll das Betriebssystem bitte alleine können.

55:53.786 --> 56:05.240
Und wir müssen dafür sorgen, dass genug Speicher für die Daten da ist, irgendwelches Puffern, Caching, Spooling ist auch noch so ein Thema.

56:05.280 --> 56:08.284
Wenn Sie Drucker haben, vielleicht mehrere Drucker in Ihrem Computer,

56:08.551 --> 56:18.663
dann möchten Sie, dass ein Programm bei einem Prozess exklusiven Zugriff hat auf einen Drucker während der Druckshop läuft.

56:18.703 --> 56:22.768
Sonst sind die Seiten oder der Inhalt auf der Seite miteinander vermanscht.

56:22.828 --> 56:37.765
Das heißt, wenn Sie jemand mal fragt, ob in Ihrem Linux oder Windows oder einem anderen modernen Betriebssystem auch kooperative Scaddling zum Einsatz kommt, dann sollte Ihnen der Druckerspule einfallen, weil das ist genau kooperativ.

56:38.318 --> 56:46.330
Egal, wie toll unser restliche Kiste ist, wenn wir einen Druckjob los schicken, dann werden wir diesen Job ausführen bis zum Ende.

56:46.350 --> 56:54.462
Und wenn er fertig sind, dann gehen wir den Drucker frei und dann kann der nächste Job gescheduled werden.

56:54.502 --> 56:56.906
Protection und Security.

56:56.926 --> 57:03.656
Protection, das ist der Schutz von Programmen gegeneinander, also von Prozessen, die da laufen.

57:03.676 --> 57:07.802
Und haben Sie schon mal von Spectrum und Meltdown gehört?

57:11.225 --> 57:12.006
Ja?

57:12.026 --> 57:12.506
Nee?

57:12.526 --> 57:13.267
Keiner?

57:13.327 --> 57:17.792
Okay, das war so ein Problem in der Hardware.

57:17.812 --> 57:19.133
So ein Übersprechen sozusagen.

57:19.173 --> 57:25.319
Stellen Sie sich vor, Sie wollen rausfinden, was das Nachbarprogramm auf dem Computer macht, der Nachbarprozess.

57:25.359 --> 57:28.482
Weil Sie wollen Passwort auch raten oder so, ne?

57:29.443 --> 57:36.270
Und jetzt hatten wir hier unsere Speicherverwaltung angeguckt und haben gesagt, nee, da oben ist er, und haben gesagt,

57:37.178 --> 57:43.148
Es gibt Daten, die sind im Hauptspeicher und das habe ich vielleicht nicht hingemalt, aber das ist auch noch Teil vom Spiel.

57:43.188 --> 57:46.593
Daten, die nicht im Hauptspeicher sind, die sind halt ausgelagert.

57:46.613 --> 57:50.039
Das war dieses Swapping.

57:50.079 --> 57:59.274
Und jetzt ist ja ein Unterschied, ob die Daten schon hier drin sind bei der Zukunftszeit oder ob sie erst eingelagert werden müssen.

57:59.354 --> 58:01.397
Also ich kriege einen Unterschied bei der Zukunftszeit raus.

58:03.166 --> 58:12.178
Und der Trick war jetzt, das war nicht auf den Speicher zu greifen, sondern dass wir das Ganze machen mit Registern, also mit Daten in der CPU.

58:12.218 --> 58:22.192
Und dass wir jetzt rausfinden, hat ein Nachbarprozess diese Daten im Speicher geholt.

58:22.212 --> 58:24.035
Und dann kann ich die Daten vielleicht auch noch lesen.

58:24.055 --> 58:26.178
Und auf die Weise kriege ich so einen Übersprechen hin.

58:26.418 --> 58:30.844
Ich kriege also raus, welche Daten hat der Nachbarprozess gerade angefasst.

58:32.140 --> 58:36.485
Und damit ist der Schutz zwischen den Prozessen aufgeweicht.

58:36.565 --> 58:48.338
Und das war eine Grundannahme, dass die modernen Prozessoren, die haben eine sogenannte Memory Management Unit, das ist ein Teil vom Prozessor, der ist zentral für die Speicherverwaltung und Betriebssystem.

58:48.378 --> 58:49.560
Und das Ding war einfach kaputt.

58:49.580 --> 58:51.562
Es war anfällig auf dies übersprechen.

58:51.622 --> 58:56.848
Also durch die richtigen Zugriffsmuster konnte ich rausfinden, welche Daten hat in der Nachbarprozess gerade angefasst.

58:57.622 --> 59:12.587
Das war also super gau, weil man das in allen Prozessoren hatte und weil damit potenziell das ganze Thema Cloud Computing und so weiter der Schutz der akt laufenden Programme gegeneinander war nicht mehr gewährleistet.

59:12.607 --> 59:18.297
Und jetzt hat man sich Gedanken gemacht, wie kann man das umgehen oder wie kann man es wieder herstellen.

59:19.812 --> 59:23.537
Und hat dabei eine Reihe von Caching Machine erst mal abgestellt.

59:23.557 --> 59:28.603
Hat er dafür gesorgt, dass die Rechner langsamer wurden, einfach um die Prozesse gegeneinander zu schützen.

59:30.165 --> 59:31.446
Später hat man die Hardware repariert.

59:32.107 --> 59:44.402
Also Protection, da geht es darum, Prozesse, die laufen und die Ressourcen benutzen, nur den zur Verfügung zu stellen, der sie wirklich benutzen darf.

59:44.686 --> 59:52.777
Wir hatten vorhin über Dateien geredet und haben gesagt, da haben wir diese Fileskriptoren und da haben wir den Leseschreibzeiger nicht.

59:52.797 --> 59:59.826
Wenn ich jetzt meinen Opensystem auf Ruf zu Ende programmiert habe, dann kommt ja hier raus irgendwie ein FD, ein Fileskriptor.

59:59.846 --> 01:00:05.714
Ein Fileskriptor ist eine kleine Zahl und diese Zahl hat in dem einen Prozess jetzt eine Bedeutung.

01:00:05.754 --> 01:00:12.162
Wenn ich jetzt die Zahl ausdrucke, in anderen Prozessen Fileskriptor mit der gleichen Zahl mache, kann ich dann auf die gleiche Datei zugreifen.

01:00:12.682 --> 01:00:14.044
Nee, kann ich nicht.

01:00:14.084 --> 01:00:22.573
Das ist also auch wieder prozessspezifisch und das Betriebssystem sorgt dafür, dass der einen recht hat beim Zugriff auf die Datei, der andere hat das Recht nicht.

01:00:22.593 --> 01:00:25.136
Das nennt man alles Protection.

01:00:25.196 --> 01:00:32.765
Security, da geht es um Sicherheit und den Zugriff von außen.

01:00:32.845 --> 01:00:38.031
Und wir brauchen, damit wir da loslegen können, eine Unterscheidung zwischen Nutzern,

01:00:38.467 --> 01:00:43.216
Nutzer werden repräsentiert durch UserIDs, vielleicht auch SecurityIDs.

01:00:43.236 --> 01:01:01.268
Eine UserID in Neonix ist einfach eine Insta-Zahl, eine UserID in Winners ist eine sogenannte Z Security Identifier, 128-Bit-Zahl, die eindeutig ist und die Sie auch nicht normal erfinden können und damit können Sie Rechte für Nutzer vergehen.

01:01:03.998 --> 01:01:14.309
Und wenn wir über verteilte Systeme reden, dann kommt auf einmal noch das Netzwerk und TSPIP ins Spiel, gibt andere Protokolle, aber das ist halt üblich.

01:01:14.369 --> 01:01:31.407
Und dann gibt es Network Operating Systems, also Betriebssysteme, die quasi darauf aufbauen, dass das in einem Netzwerk unterwegs sind und Nachrichten zwischen verschiedenen Knoten hin und her tragen und den Eindruck erwecken, wir hätten ein einziges zusammenhängendes System.

01:01:32.585 --> 01:01:50.155
Und in diese Kategorie der Netzwerksysteme passen auch geklastete Systeme, solche, wo man sagt, wir haben irgendwie eine zentrale Ressource, wie die Historisch-Area-Network zentral und können jetzt den gleichen Job hier rechnen oder da oder da.

01:01:50.573 --> 01:02:03.082
Weil macht man so was, wenn man zum Beispiel eine Web-Server Farm betreibt und sicherstellen will, dass der Ausfall eines Web-Servers nicht zufolge hat, dass der Dienst runterfällt.

01:02:03.122 --> 01:02:05.768
Gibt es zustandsbehaftete Dienste, zustandslose Dienste?

01:02:05.788 --> 01:02:08.194
Haben Sie schon mal von den Amazon One Click Patent gehört?

01:02:11.802 --> 01:02:22.881
Ich bin vor einer ganzen Zeit mal mit der Münchner Anwaltskanzlei Patentanwälte ins Geschäft gekommen, die dieses Patent gemacht haben.

01:02:22.901 --> 01:02:24.845
Da ging es also irgendwie um Gutachten.

01:02:24.905 --> 01:02:31.076
Aber was steckt hinter diesem One-Click-Patent?

01:02:31.096 --> 01:02:34.722
Wenn Sie sich vorstellen, Sie sind jetzt gerade mal in einem Online-Shop.

01:02:35.292 --> 01:02:43.545
und wollen diesen Online-Shop implementieren, dann müssen Sie ja sowas wie ein Shopping-Grad, also ein Einkaufswagen bauen.

01:02:43.605 --> 01:02:49.214
Und in dem Einkaufswagen sind die Items drin, die der Mensch da gerade sich angeguckt hat, schon klar.

01:02:49.234 --> 01:02:51.758
Aber am besten auch noch die Bezahlinformation.

01:02:51.778 --> 01:02:57.107
Und jetzt ist die Frage, wo speichern Sie den Einkaufswagen?

01:02:57.167 --> 01:02:59.190
Erste Idee, wir speichern den bei uns auf dem Server.

01:03:00.352 --> 01:03:01.313
Dumme Idee.

01:03:01.353 --> 01:03:02.174
Warum?

01:03:02.194 --> 01:03:03.655
Sie können nicht skalieren.

01:03:03.696 --> 01:03:07.640
Da können sie bis 1000 oder bis 10.000, aber gibt es einen Limit.

01:03:07.680 --> 01:03:12.545
Doppeltumme Idee, weil wenn ihr Server ausfällt, dann ist alles weg.

01:03:12.885 --> 01:03:15.708
Und jetzt ist das cool.

01:03:15.728 --> 01:03:19.773
Und vielleicht haben Sie sich schon mal URLs genauer angeguckt.

01:03:19.813 --> 01:03:24.958
Da gibt es ja so eine Möglichkeit, dann mit einem Fragezeichen auf weiteren Krämpeln in die URL reinzuschreiben.

01:03:25.917 --> 01:03:34.647
Die Idee ist, wir verpacken den Einkaufswagen einfach in der URL und geben das dem Klienten mit.

01:03:34.687 --> 01:03:38.631
Das heißt, die Daten werden gar nicht auf dem Server gespeichert, sondern im Klienten.

01:03:38.671 --> 01:03:44.758
Das ist eine geniale Idee, weil unser Server jetzt auf einmal zustandslos ist.

01:03:44.778 --> 01:03:52.347
Und Sie können skalieren bis dahin aus und Sie können insbesondere auch tolerieren, dass ein Server ausfällt, weil dann machen Sie einfach mit dem nächsten weiter.

01:03:53.390 --> 01:04:10.541
Und wie man das Ganze jetzt so kudiert, dass man bei Amazon auf sofort laufen klickt und danach schickt er ihn irgendwelchen Krempel nach Hause, dass also die Bezahlinformationen mit in dieser URL vergraben ist auf eine sichere Weise.

01:04:10.561 --> 01:04:11.382
Dafür haben die ein Patent.

01:04:12.695 --> 01:04:15.922
Jetzt kann man sagen, früher hätte ich ja selber drauf kommen können, aber vielleicht doch nicht.

01:04:15.982 --> 01:04:24.741
Also das ist schon relativ coole Nummer und dahinter steckt die Idee oder was man sich merkt ist.

01:04:24.801 --> 01:04:30.653
In solchen Klassesystemen hat man immer dann ein leichtes Leben, wenn man schafft, diese Server zustandslos zu halten.

01:04:31.544 --> 01:04:52.790
Und da gibt es dann auch vorgefertigte Lösungen, also bei Microsoft heißt das zum Beispiel Network Load Balancing, da macht man folgendes, man hat einen Bündel von Servern und die hängen alle an der gleichen IP-Adresse und die hören sozusagen einkommende Nachrichten.

01:04:52.831 --> 01:05:01.281
Und jetzt werden die untereinander kommunizieren, also eine sogenannte Multicast-Adresse, und werden sich Lebendigkeitsnachrichten schicken.

01:05:01.463 --> 01:05:04.746
Also man kriegt über mit ist der Nachbar noch da.

01:05:04.766 --> 01:05:12.733
Und gleichzeitig, wenn eine einkommende Nachricht ist, dann gucken Sie sich die alle an und rechnen Modulo Serverzahl.

01:05:12.753 --> 01:05:20.199
Und das wird der dritte Server antworten, wenn die Adresse Modulo Serverzahl gleich drei ergibt.

01:05:20.259 --> 01:05:22.201
Und sonst wird der zweite antworten oder der vierte.

01:05:22.221 --> 01:05:28.126
Also Sie machen eine Lastbalansierung einfach anhand der IP-Adresse Ihres Klienten.

01:05:28.386 --> 01:05:31.369
Damit kommt Ihre Anfrage immer auf den gleichen Server raus.

01:05:32.497 --> 01:05:49.201
Und wenn jetzt bei den Lebenigkeitsnachrichten, ein Server nicht mehr antwortet, dann wird der Nachbar einfach den Job übernehmen und sagen, ich mache jetzt nicht nur Modulo Server-Zahl gleich 3, sondern ich mache auch mal Modulo Server-Zahl gleich 4 und bearbeite dessen Arbeit einfach mit.

01:05:49.262 --> 01:05:52.967
Dann können Sie den Server günstlich neu starten und geht es halt weiter.

01:05:52.987 --> 01:05:59.837
Also das können Sie bei Microsoft als Produkt kaufen, gibt es andere Lösungen, aber so baut man sozusagen solche Cluster-Systeme auf.

01:06:02.348 --> 01:06:10.117
Ja, das ist eine gute Frage.

01:06:10.137 --> 01:06:12.760
Da muss man ein bisschen noch darüber reden, was IP-Adressen sind.

01:06:12.780 --> 01:06:18.367
Haben Sie vielleicht schon mal gehört bei HKK, Glas-ABC-Adressen und so ein Krämpel?

01:06:18.387 --> 01:06:24.254
Nicht, also innerhalb eines Subnetzes werden die ja in der Regel aufsteigend vergeben einfach.

01:06:24.294 --> 01:06:29.520
Und da kann man schon davon ausgehen, dass mit einer gewissen Wahrscheinlichkeit die gleich verteistet.

01:06:29.500 --> 01:06:36.771
Also es ist klar, die 255 ist was Spezielles und die 1 ist was Spezielles, die werden Sie nicht so oft sehen.

01:06:36.851 --> 01:06:42.380
Aber die Restlichen, die werden schon irgendwie der Reihe nach vergeben werden.

01:06:42.400 --> 01:06:43.341
Genau.

01:06:43.361 --> 01:06:50.773
Und jetzt kann man Klass dann auch aus anderen Gründen bauen, zum Beispiel für High Performance Computing, wo man einfach sagt, der Job ist so groß, dass sich die Aufgabe auf mehr Rechner verteilen muss.

01:06:50.813 --> 01:06:56.942
Und dann gibt es halt eine ganze Theorie, die sich wieder damit beschäftigt, wie man diesen Speicher hier

01:06:58.103 --> 01:07:01.387
den ganzen Server zur Verfügung stellt, also die Storage.

01:07:01.427 --> 01:07:07.836
Und was wir hier sehen, ist so ein Shared Disk System, aber es gibt eben auch Shared Nussing Systeme.

01:07:07.856 --> 01:07:08.777
Was ist das?

01:07:08.797 --> 01:07:13.644
Da haben die Computer keine gemeinsamen Ressourcen.

01:07:14.024 --> 01:07:18.030
Und wenn man sagt, wir wollen doch gemeinsame Ressourcen haben, ja, da muss man die in Software nachbauen.

01:07:18.070 --> 01:07:24.919
Da muss man sich wieder im Protokoll überlegen, wie Dateien zum Beispiel kopiert werden von einem Knoten auf dem nächsten.

01:07:24.939 --> 01:07:25.039
Also,

01:07:27.398 --> 01:07:30.409
Inhalt für eine nächste weitere Vorlesung.

01:07:30.429 --> 01:07:38.337
Gut, damit sind wir also mit diesem ersten Einführungsteil durch und jetzt geht es natürlich weiter und da gucken wir ein bisschen in die Geschichte.

01:07:50.585 --> 01:08:02.883
Und da fangen wir wirklich ganz weit hinten an, also 1801 und 1822, die analytische Engine von Charles Babbage, von wegen, wer hat den ersten Computer gebaut.

01:08:02.903 --> 01:08:15.721
Die Fotos hier, die sind nebenbei aus dem IBM Museum, die zeigen solche Lochkarten und dann auch geredet die Lochkarten verarbeiten können in Wöblingen.

01:08:15.781 --> 01:08:19.326
Aber ganz am Anfang war der

01:08:20.453 --> 01:08:23.140
Wäbstuhl, die Vorlage.

01:08:23.200 --> 01:08:28.453
Und wenn sie da irgendwie in den Museum gehen, schlesische Weberaufstand, haben Sie davon schon mal gehört?

01:08:29.235 --> 01:08:30.999
Genau, das war die Maschinenstommer rein.

01:08:31.019 --> 01:08:32.202
Da hat man gesagt, also hier

01:08:32.587 --> 01:08:35.111
Die Arbeitsplätze gehen verloren.

01:08:35.131 --> 01:08:38.296
Wir müssen die Maschinen kaputt machen, weil die sind teuflisch.

01:08:38.356 --> 01:08:40.359
Ist so ein bisschen wie mit ChatGPT.

01:08:40.459 --> 01:08:45.747
Und plus 200, nee, neuer doch, 200 Jahre zurück.

01:08:45.767 --> 01:08:53.659
Danach hat man, also wie wurden solche mechanischen Webstühle programmiert, mit Holzplatten.

01:08:53.679 --> 01:08:57.885
Und diese Holzplatten, die waren irgendwie aneinander gehäftet und auf die Weise konnte man verschiedene Muster.

01:08:57.865 --> 01:09:02.131
Und die analytische Engine von Charles Babich hat diese Idee aufgegriffen.

01:09:02.151 --> 01:09:05.496
Die hat interessanterweise in Dezimalzahlen gerechnet.

01:09:05.516 --> 01:09:08.360
Und man hat sie versucht zu bauen.

01:09:08.400 --> 01:09:10.162
Man konnte damals nicht präzise genug bauen.

01:09:10.222 --> 01:09:14.689
Sie hätte funktioniert.

01:09:14.749 --> 01:09:17.072
Aber war halt doch ein Gedankenexperiment.

01:09:17.997 --> 01:09:26.646
Und 1890 kam dann der Zensus, also die Volkszählung in Amerika ins Spiel.

01:09:26.706 --> 01:09:36.036
Und bei Gelingheit zeige ich Ihnen mal den 100 Jahre IBM-Film, der sozusagen Zeitzeugen referenziert aus all diesen Jahren.

01:09:36.076 --> 01:09:42.904
Und da ist die Aussage, ohne die IBM hätte es keine Volkszählung und keine Social Security gegeben.

01:09:43.324 --> 01:09:45.186
Also die Sozialversicherung hat darauf aufgebaut.

01:09:45.622 --> 01:09:56.277
Und tatsächlich ist es ja so, dass in Amerika die Social Security ID eine eindeutige Bezeichnung für jeden Bürger ist.

01:09:57.339 --> 01:10:00.403
Und wie gesagt, die deutsche Hollerit war damals Auslöser.

01:10:00.423 --> 01:10:08.856
Und dann gab es die Tabulating Machine Company, die dann später mal IBM wurde, wo man halt Lochkarten verarbeitet hat.

01:10:08.896 --> 01:10:11.640
Das könnte man mit solchen Lochkarten machen und konnte Daten einlesen.

01:10:11.660 --> 01:10:13.442
Man konnte addieren, subtrahieren und so weiter.

01:10:13.462 --> 01:10:15.325
Alles das, was der

01:10:15.592 --> 01:10:21.484
kaufmännische Taschenrechner macht sozusagen und hat dann neue Lochkarten ausgegeben.

01:10:21.505 --> 01:10:35.895
Das ganze Ding war so erfolgreich, dass man bis in die 1960er, 70er Jahre, die noch produziert hat und in großen Stückzahlen verkauft hat, weil die eben ein Problem gut gelöst haben, nämlich das Problem des kaufmännischen Rechnens.

01:10:44.127 --> 01:10:50.539
Das ist leider so, dass viele Entwicklungen in der Informatik durch das Militär und durch den Militärischen Einsatz getrieben sind.

01:10:50.559 --> 01:11:00.058
Bei der Rechner Architektur war es so, dass man die Tabellen für die Ausrichtung von Geschützten berechnen wollte und zwar offline.

01:11:00.098 --> 01:11:03.925
Also man hat dann gesagt, wenn ich das Ziel in so einer Distanz

01:11:04.242 --> 01:11:10.632
bekämpfen will, dann muss ich den Vorhalt der Winkel folgendermaßen einstellen und dafür hat man Tabellen ausgerechnet.

01:11:10.672 --> 01:11:13.517
Das hat man auf diesem Mark 1 gemacht.

01:11:13.537 --> 01:11:26.858
Und ein Grace Hopper ist vielleicht als Name auch bekannt, weil nach ihr heute Programme benannt sind, Konferenzen, wo man vor allen Dingen weibliche

01:11:27.952 --> 01:11:32.239
Informatikerinnen unterstützen will.

01:11:32.279 --> 01:11:35.825
Weiß nicht, haben Sie Hidden Figures mal gesehen, diesen Film?

01:11:35.845 --> 01:11:38.889
Genau, da kommt ein bisschen was dazu vor.

01:11:38.909 --> 01:11:46.201
Und da gab es dann sozusagen den ersten Compiler, den ersten Bug, klar, den ersten Compiler und die Sprache Kobol.

01:11:46.221 --> 01:11:52.491
Kobol ist eine Sprache, manche Leute sagen, immer noch die am meisten verbreitete Programmiersprache heute.

01:11:53.095 --> 01:11:59.023
weil die nämlich in so einer Art Englisch, also kommerzielle Berechnungen gut darstellen kann.

01:11:59.704 --> 01:12:01.226
Cobalt hat ein paar interessante Ideen.

01:12:01.246 --> 01:12:03.950
Eine war das sogenannte Common Area.

01:12:03.970 --> 01:12:09.557
Also man hat gesagt, wenn man verschiedene Programme laufen lässt, dann haben die diesen Speicher da oben.

01:12:09.577 --> 01:12:12.701
Ein Bereich, der ist für alle lesbar schreibbar.

01:12:12.741 --> 01:12:17.027
Also auf die Weise kann man Daten zwischen Programmen austauschen, zwischen Prozessen austauschen.

01:12:19.235 --> 01:12:39.044
Dann zu, so wie gesagt, mit seinen Maschinen und Plak-Plan-Kalkül als Problemiersprache und dann der John von Neumann mit der ENIAC und der ADVAC und dem Stored-Programm-Konzept und dem Problem des Neumannischen Flaschenhals.

01:12:39.084 --> 01:12:43.671
Dann haben Sie vielleicht schon mal von Analog-Rechtern gehört oder vielleicht auch nicht.

01:12:43.711 --> 01:12:46.675
Oder warum ist ein Rechner eigentlich so, wie er ist?

01:12:46.695 --> 01:12:48.077
Wie funktioniert ein Rechner überhaupt?

01:12:48.547 --> 01:12:50.330
Alles geht los mit dem Taxsignal.

01:12:50.350 --> 01:12:55.900
Wir haben den Takt und dann werden wir eine Instruktion lesen und zwar an der Stelle, wo der Programmkonto hin zeigt.

01:12:55.920 --> 01:13:09.002
Dann werden wir diese Instruktion in Speicherladen, dann werden wir ins Registerladen, Instruktionsregister, wenn wir versuchen zu verstehen, was gemeint ist und dann werden wir Operandennachladen und dann werden wir die Instruktion ausführen.

01:13:09.674 --> 01:13:20.347
Und dann gab es HardWired-Kontroll, also die Control Unit in dem Prozessor Machtes, die konnte man festvertratet programmieren oder mikroprogrammiert implementieren.

01:13:20.367 --> 01:13:24.712
In modernen Systemen sind die mikroprogrammiert.

01:13:24.772 --> 01:13:27.376
Aber so wird gerechnet.

01:13:27.396 --> 01:13:39.090
Und jetzt gibt es aber Probleme, also gerade so etwas wie Gleitkommaberechnung, die lassen sich viel besser darstellen als ein Netzwerk von Konsatoren und Widerständen.

01:13:39.627 --> 01:13:41.772
also als elektrische Schaltung.

01:13:41.812 --> 01:13:51.333
Wo ich sage, meine Berechnung ist einfach repräsentiert durch die Ausgangsspannung oder die Spannung am Ende der Schaltung.

01:13:51.353 --> 01:13:53.558
Wie lange braucht diese Schaltung?

01:13:53.578 --> 01:13:55.943
Für die Propagation oder für das Berechnen?

01:13:55.963 --> 01:13:58.328
Ja gar nicht lange, also sofort da.

01:13:58.966 --> 01:14:09.756
Und das war also eine Zeit lang das große Thema, dass man sagte, wir haben Analogrechner als die bessere Lösung, insbesondere für diese militärischen Einsatzfälle.

01:14:09.776 --> 01:14:22.868
Und danach gab es aber diesen Schwenken hin zu sequenzialen Verarbeitungen, klassische von Neumann Computertakt getrieben, programmiert in Assemblersprache.

01:14:22.908 --> 01:14:27.572
Und als Ein- und Ausgabe hatte man also Lampen und Schalter.

01:14:28.227 --> 01:14:31.531
Dann hatte man noch Lochkarten, Leser und Schreiber.

01:14:31.571 --> 01:14:37.539
Das ist der erste ernsthafte Computer mit dem X zu tun hat.

01:14:37.559 --> 01:14:40.803
Das war eine PDP-11, also eine Maschine von Deck.

01:14:40.823 --> 01:14:43.065
Und die hatte 16 Schalter.

01:14:43.105 --> 01:14:46.630
Und mit diesen Schaltern hatte man die Startadresse eingetragen.

01:14:46.650 --> 01:14:49.814
Und an dieser Startadresse war jetzt der Bootcode für das Betriebssystem.

01:14:49.854 --> 01:14:52.477
Und dann ging es halt los.

01:14:52.497 --> 01:14:56.462
Also das ist gar nicht so lange her.

01:14:58.130 --> 01:15:02.267
Das Laden eines neuen Programms, das ist eine Operation, die lange dauert.

01:15:03.311 --> 01:15:06.705
Und als wir vorhin über Klassensysteme, über High Performance Computing geredet haben,

01:15:07.478 --> 01:15:09.522
oder auch über Quantum Computing.

01:15:09.542 --> 01:15:18.800
Wenn Sie sich solche Knochen angucken, die heute sozusagen eine der Fahnenstange sind, dann rechnen Sie super schnell, aber die brauchen halt eine halbe Stunde, bis das Programm geladen ist.

01:15:18.820 --> 01:15:20.163
Und dann geht es los.

01:15:20.183 --> 01:15:28.980
Also das Betreiben eines Rechners ist mehr, als wir das heute von einem Desktop-Computer gewöhnt sind.

01:15:29.635 --> 01:15:34.104
Und das Programm hatte die vollständige Kontrolle über die Maschine.

01:15:34.124 --> 01:15:41.399
Das heißt, man musste sich Rechenzeit reservieren und man hatte lange Setupzeit.

01:15:43.123 --> 01:15:49.095
Ich hatte gesagt Mainframes 1964 irgendwie die Rechner, die heute die Welt bewegen immer noch.

01:15:50.037 --> 01:15:54.883
Die haben eine eigene Sprache dafür sich ausgedacht, die JCL, die Job-Control-Language.

01:15:54.923 --> 01:16:01.030
Und mit der Job-Control-Language beschreibt man, welche Daten gehören denn zum Lauf eines Programms.

01:16:01.090 --> 01:16:07.398
Also welche Bänder müssen aufgelegt werden, welche Lochkarten müssen eingelegt werden, welche Platten müssen wir referenzieren usw.

01:16:07.438 --> 01:16:09.681
Und dann geht's los.

01:16:09.701 --> 01:16:12.724
Gibt's so was Ähnliches in Unix oder in Windows?

01:16:12.745 --> 01:16:13.986
Haben Sie sowas schon mal entdeckt?

01:16:15.198 --> 01:16:15.819
Eigentlich nicht.

01:16:15.839 --> 01:16:20.223
Wir gehen davon aus, dass alle Daten, die wir verarbeiten wollen, online und immer vorhanden sind.

01:16:20.243 --> 01:16:22.206
Also wir haben Dateien, die sind halt da.

01:16:22.226 --> 01:16:29.914
Vielleicht ist Mount Command, dass ich sage, ich muss ein Dateisystem erst mounten, bevor es losgeht.

01:16:29.934 --> 01:16:33.178
Betriebssystem an der Grenze zwischen hardware und software.

01:16:33.198 --> 01:16:41.847
Es gibt halt die Maschinensprache, die ganze CPU, Architektur und so weiter nach unten hin.

01:16:42.434 --> 01:16:47.318
Die Komplexität der Hardware soll verborgen, verbergen, verborgen sein.

01:16:47.378 --> 01:16:49.400
Und dann haben wir unsere Anwendungen.

01:16:49.440 --> 01:16:54.264
Und dazwischen das Betriebssystem mit Systemprogrammen.

01:16:54.284 --> 01:17:00.089
Und da hatten wir vorhin Compiler und Editor und Kommando in der Präter, die Shell schon erwähnt.

01:17:00.109 --> 01:17:06.115
Welche Shells fallen Ihnen so ein?

01:17:06.135 --> 01:17:08.677
Ja, Z Shell, Born Shell, irgendwelche so was.

01:17:08.717 --> 01:17:12.340
Also SH in Windows gibt es auch ein Shell.

01:17:16.133 --> 01:17:19.277
Ja, PowerShell, cmd.exe.

01:17:19.297 --> 01:17:23.823
Wenn Sie nachgucken in der Registrierung, was die Shell ist in Windows, da steht da Explorer.exe.

01:17:23.843 --> 01:17:25.164
Der Explorer ist die Shell in Windows.

01:17:25.184 --> 01:17:26.586
Das ist halt eine grafische Shell.

01:17:26.666 --> 01:17:30.130
Also eine Shell kann grafisch funktionieren oder kann Kommando zeigen.

01:17:30.150 --> 01:17:32.393
Also CLI, sagt man an.

01:17:32.413 --> 01:17:33.995
Kommandländer fees.

01:17:34.055 --> 01:17:36.218
Aber es ist ein Kommando Interpreter.

01:17:39.944 --> 01:17:52.403
Wie gesagt, Stapelverarbeitung, als gewöhnlicher Nutzer konnte man solche Maschinen nicht anfassen, sondern gab es auch noch Menschen, das waren die Operator.

01:17:52.423 --> 01:18:00.436
Und man hat dann sein Lochkartenstapel dem Operator gegeben und seine Bänder und der hat die dann aufgelegt und danach konnte man den Job laufen lassen.

01:18:00.496 --> 01:18:03.741
Und die Printouts, die hat man hinterher vom Operator wieder zurückgekriegt.

01:18:03.991 --> 01:18:07.094
Also die ungewaschenen Massen durften sozusagen die Rechner nicht anfassen.

01:18:08.636 --> 01:18:10.437
Das hat sich dann im Laufe der Zeit geändert.

01:18:11.658 --> 01:18:15.082
Multi-Programmierung hatten wir schon gerade gesehen.

01:18:15.102 --> 01:18:17.905
Und was gibt es denn dann noch?

01:18:17.925 --> 01:18:21.288
Also am Anfang waren die Betriebssysteme so drauf, dass sie Stapelverarbeitung konnten.

01:18:21.308 --> 01:18:23.290
Danach kam Multi-Programmierung.

01:18:23.310 --> 01:18:31.838
Also die Idee, wir lassen mehrere Programme gleichzeitig laufen, damit wir Ein- und Ausgabeaktivitäten und Rechenaktivitäten miteinander verschränken können.

01:18:32.527 --> 01:18:36.774
Dann kam eine relativ coole Idee, nämlich dieses Timesharing.

01:18:36.814 --> 01:18:40.340
In einem Mainframe ist es tatsächlich nur ein spezielles Programm.

01:18:40.360 --> 01:18:42.884
Das ist TSO, die Timesharing Option.

01:18:42.904 --> 01:18:45.168
Dieses Programm bedient dann das Terminal.

01:18:45.188 --> 01:18:50.156
Und es kann dann viele Terminals bedienen und kann damit viele Nutzer bedienen.

01:18:50.216 --> 01:18:56.627
Also, wenn wir erstmal zwei Programme laufen lassen können, dann können wir auch verschiedene Nutzer bedienen.

01:18:59.527 --> 01:19:04.824
Und Prozesssteuerung, wie gesagt, Bionscope in dieser Veranstaltung.

01:19:04.844 --> 01:19:08.616
Hier wollen wir zeitkritische Prozesse behandeln.

01:19:10.242 --> 01:19:11.325
Zur Stapelverarbeitung.

01:19:12.098 --> 01:19:19.766
gibt es halt die Job-Kontroll-Language und dann gibt es Instruktionen, was wir hier alles benutzen sollen.

01:19:19.806 --> 01:19:25.051
Es gibt den User-Mode und den Monitor-Mode oder einen System-Mode, Kernel-Mode, Supervisor-Mode.

01:19:25.091 --> 01:19:34.281
Also die Art, wie man Betriebssystem interner und Nutzerprogramme gegeneinander schützt, das macht man durch Betriebsarten des Prozessworts.

01:19:34.341 --> 01:19:37.144
Und in der Vergangenheit waren da

01:19:37.546 --> 01:19:38.988
vier Betriebsarten üblich.

01:19:39.008 --> 01:19:42.434
Danach war es eine ganze Zeit lang zwei.

01:19:42.454 --> 01:19:43.716
Dann kam die Virtualisierung.

01:19:43.756 --> 01:19:45.860
Was ist das spannende Ding bei Virtualisierung?

01:19:45.880 --> 01:19:50.367
Wenn wir uns vorstellen, wir haben ein Betriebssystem mit einem User-Mode und einem Kernel-Mode.

01:19:50.407 --> 01:19:52.050
Und jetzt wollen wir eine virtuelle Maschine laufen lassen.

01:19:52.110 --> 01:19:53.092
Was macht die denn?

01:19:53.132 --> 01:19:58.020
Das ist eine Applikation, die wieder ein Betriebssystem laufen lässt mit dem User-Mode und Kernel-Mode.

01:19:58.280 --> 01:20:04.110
Und wie kriegen wir denn jetzt heraus, dass der Kernel-Mode von der virtuellen Maschine dran ist?

01:20:05.086 --> 01:20:12.954
Wenn wir da einfach unseren gewöhnlichen Kernelnot laufen lassen, das wäre fatal, weil dann könnte dieses Gastbetriebssystem die Kontrolle über die gesamte Hardware übernehmen.

01:20:14.455 --> 01:20:19.700
Das heißt, wir lassen das Gastbetriebssystem niemals im Kernelnot laufen, sondern immer nur im User-Motor.

01:20:19.720 --> 01:20:22.603
Jetzt gehen gewisse privilegierte Instruktionen nicht.

01:20:23.004 --> 01:20:26.507
Die sollen dann einen Treff auslösen, da müssen wir die emulieren.

01:20:26.527 --> 01:20:30.351
Leider machen das nicht alle Prozessoren richtig.

01:20:30.618 --> 01:20:42.800
Und die Lösung, und IBM hat es von Anfang an eingebaut, die wir heute finden, ist, dass wir sagen, wir haben nicht zwei Protection Modus, sondern wir haben drei oder bis zu nicht vier, sondern fünf.

01:20:42.820 --> 01:20:49.572
Und wir haben noch so einen Ring minus eins, heißt der dann, wo wir sagen, das ist der Protection Modus für den Hypervisor, für die Virtualisierung.

01:20:53.298 --> 01:20:57.683
Aber was man sich merken muss, es gibt mindestens zwei Betriebsarten.

01:20:57.703 --> 01:21:04.931
Eine privilegierte, wo alles erlaubt ist, macht Betriebssystem und eine, wo nicht alles erlaubt ist für die User.

01:21:04.951 --> 01:21:09.616
Und das war der Schlüssel, damit war die verschiedenen Prozesse, die hier in unserem Speicherschutz rumfahren, gegeneinander schützen können.

01:21:10.197 --> 01:21:17.685
Ist klar, wenn jeder Prozess dieses Limit und Offset neu programmieren durfte, dann wäre unser ganzer Speicherschutz hinfällig.

01:21:19.994 --> 01:21:27.846
Das ist jetzt ein Bild zur Multi-Programmierung, wie es halt besser geht, wenn man Sachen miteinander verschränken kann.

01:21:27.886 --> 01:21:43.690
Und hier sieht man einfach nur Laufzeiten, die sich dann verkürzen, wenn ich diese Jobs eben nicht sequenzial hintereinander habe, wenn ich den menschlichen Overhead los bin erstens, wenn ich den menschlichen Overhead nur einmal mache und dafür eine Stapelverarbeitung ist schon ein bisschen besser.

01:21:43.973 --> 01:21:52.783
Weil der Mensch ist ja sowieso immer Störfaktor, aber wenn ich das Ganze noch miteinander verschränke, dann wird es halt am allerbesten.

01:21:52.803 --> 01:21:56.747
Also während der eine Aero macht, lasse ich halt den nächsten gleich wieder laufen.

01:21:56.867 --> 01:22:06.538
Hier habe ich Job 1 laufen, jetzt habe ich es aufgebrochen und während Job 2 läuft, lasse ich Job 1 schon wieder ein bisschen laufen, dann lasse ich Job 2 laufen und so weiter und sofort verstehen wir.

01:22:07.514 --> 01:22:12.549
Also Multi-Programmierung ist toll, damit es schneller geht, Timestring ist toll, damit wir mehrere Nutzer bedienen können.

01:22:12.589 --> 01:22:20.292
Weil wir nämlich irgendwann den Punkt erreicht haben, dass die Prozessoren so schnell waren, dass der Nutzer sowieso nicht mehr merkt, dass er nicht den ganzen Prozessor hat.

01:22:22.364 --> 01:22:24.488
Gibt es immer noch Stapelverarbeitungssysteme?

01:22:24.528 --> 01:22:25.630
Ja, ganz genau.

01:22:25.650 --> 01:22:26.311
Gibt es noch.

01:22:26.331 --> 01:22:41.158
Also, wenn wir High Performance Computing machen sowieso, aber auch die SAP mit ihrem R3-System oder S4-Hana, alles die gleiche Brühe, natürlich machen die in Stapelverarbeitung, die machen eigentlich was ganz Interessantes.

01:22:41.178 --> 01:22:46.127
Wenn Sie so ein R3-System angucken, dann lässt es den Job laufen.

01:22:46.782 --> 01:22:51.928
und guckt nach einer kurzen Zeit nach, wie es dem Job geht.

01:22:51.968 --> 01:22:53.069
Also zum Beispiel nach 10 Sekunden.

01:22:53.470 --> 01:22:58.335
Wenn das Ergebnis nicht fertig hat, wird er abgebrochen und wird auf einem neuen Computer neu gestartet.

01:22:58.375 --> 01:22:59.476
Da darf er eine Minute laufen.

01:22:59.496 --> 01:23:05.363
Wenn er immer noch nicht fertig ist, wird er abgebrochen und wird auf einem neuen Knoten gestartet und da darf er jetzt laufen, bis er wirklich fertig ist.

01:23:05.423 --> 01:23:06.624
Warum macht man das?

01:23:06.644 --> 01:23:11.710
Damit die lang laufenden Jobs trotzdem fair behandelt werden.

01:23:15.115 --> 01:23:20.582
Und TPM ist ein Transaktionsverarbeitungsmonitor von der IWM.

01:23:20.602 --> 01:23:25.588
Dann gab es einen oder zwei so ganz zentralen Betriebssysteme.

01:23:25.608 --> 01:23:36.082
Das CTSS ist ein Vorläufer, der MIT entwickelt wurde auf einem Großrechner, der viele Konzepte vorweggenommen hat, die man heute in Betriebssystemen findet.

01:23:36.102 --> 01:23:37.984
Und der Nachfolger war Multics.

01:23:38.099 --> 01:23:44.365
Und wenn Sie sich schon mal gefragt haben, warum heißt es Unix?

01:23:44.385 --> 01:23:53.134
Sie haben gesagt, und am Anfang wurde es auch wirklich mit ICS geschrieben, von dem, was Muldix gleichzeitig konnte, wollen wir wenigstens eins können, deshalb Unix.

01:23:53.154 --> 01:23:56.898
Wir wollen nicht viele Prozesse gleichzeitig laufen lassen, sondern überhaupt nur einen.

01:23:56.918 --> 01:24:04.005
Und Muldix ist aber nach wie vor sozusagen in Ein-Einflussreich für ganz viele

01:24:03.985 --> 01:24:07.889
danach entstandene Entwicklung.

01:24:07.909 --> 01:24:12.053
Und jetzt ist die Zeit gleich rum und dieses Bild braucht ganz viel, da kann man ganz viele Geschichten erzählen.

01:24:12.093 --> 01:24:14.935
Ich reiß mich ja so ein bisschen zusammen.

01:24:14.955 --> 01:24:19.139
Fangen wir mal an und gucken zur IBM OS 360.

01:24:19.180 --> 01:24:23.864
Das Betriebssystem, was sozusagen als Zeichen die Windrose hatte.

01:24:23.904 --> 01:24:25.145
Die Windrose 360 Grad.

01:24:25.185 --> 01:24:28.649
Man wollte alles das rechnen können, was jemals gebraucht wird.

01:24:28.669 --> 01:24:31.191
Das war sozusagen der große Wurf.

01:24:31.171 --> 01:24:38.845
Der hat auch die Welt verändert, 1964, aber hat halt nicht gleich richtig funktioniert, sondern was gleich funktioniert hat, war DOS 360.

01:24:38.866 --> 01:24:40.995
Es war ein kleineres Betriebssystem.

01:24:41.802 --> 01:24:49.250
dann nicht das ist ein und Ausgabe Kontrollsystem, IOControllsystem, spezialisierte Betriebssysteme.

01:24:49.270 --> 01:25:00.182
Also vor 1964 kann man sich so vorstellen, bedeutete ich kaufe einen neuen Rechner, wenn man das Geld hatte, man schreibt alles auf Herr Neu.

01:25:00.202 --> 01:25:04.847
Also der ganze Begriff Kompatibilität aufwärts abwärts, war noch nicht erfunden.

01:25:04.867 --> 01:25:06.669
Alles Neu.

01:25:06.689 --> 01:25:09.092
Dann kam CDSS als großes Projekt und mit dem

01:25:10.861 --> 01:25:14.852
Multis Betriebssystem aus dem dann hervorgegen Junix.

01:25:14.892 --> 01:25:22.592
Junix V7, das war die Version, die von AT&T sozusagen vertrieben wurde und aus diesem Junix wurde dann

01:25:23.146 --> 01:25:31.362
In der Variante, die heißt Berkeley System Distribution, die University of California in Berkeley hat eine eigene UNIX Variante gebaut.

01:25:31.382 --> 01:25:38.596
4.2 BSD ist ganz wichtig, weil da wurden Sockets erfunden, also das Thema Netzwerk-Kommunikation.

01:25:38.616 --> 01:25:42.403
Gleichzeitig aus dem ET&T UNIX wurden dann System 3, System 5.

01:25:44.662 --> 01:25:47.306
Da gibt es einen anderen Querbezug.

01:25:47.326 --> 01:25:48.868
Das sehen wir hier schon.

01:25:48.908 --> 01:25:50.390
Hier gibt es Xenics.

01:25:50.411 --> 01:25:53.074
Xenics war ein Betriebssystem von der Firma Microsoft.

01:25:53.094 --> 01:25:56.139
Microsoft war eine Zeit lang der größte Unix-Hersteller auf dem Planeten.

01:25:56.179 --> 01:25:58.062
Kann man sich auch nicht so vorstellen mehr.

01:25:58.102 --> 01:26:08.998
Aber das war ein Betriebssystem, was auf 88, 8086 und 8016 lief, also auf ganz kleinen Prozessoren.

01:26:08.978 --> 01:26:14.048
Dann gab's die Firma, also das hier drüben ist IBM, gewissermaßen.

01:26:14.108 --> 01:26:17.876
Das hier ist irgendwie AT&T und dann gab's System 5.4.

01:26:18.657 --> 01:26:21.984
Da kam noch ein anderes Betriebssystem dazwischen, das hier SanOS.

01:26:22.004 --> 01:26:24.168
Sanos steht für Stanford University Network.

01:26:24.188 --> 01:26:27.274
Das war Andy von Bechtholz sagen, wer das mal gehört hat in Deutschland.

01:26:27.254 --> 01:26:34.531
ausgewandelt ist, dort proviert hat, eine Firma gegründet hat und die hat für lange Zeit wirklich das wissenschaftliche Rechnung dominiert.

01:26:34.551 --> 01:26:39.222
Und jetzt haben sich zwei zusammengetan, nämlich San und Eti und Tih und haben Solaris erfunden.

01:26:39.262 --> 01:26:45.837
Solaris gibt es heute auch nicht mehr, weil es wurde am Ende von Oracle aufgekauft und Oracle ist sozusagen

01:26:45.817 --> 01:26:47.981
Nicht so toll.

01:26:48.001 --> 01:26:53.650
Aber das war für eine Zeit lang das Marktbeherrschende Betriebssystem.

01:26:53.670 --> 01:27:01.463
Jetzt stellen wir sich vor, es gab ja noch HP, es gab DECK, es gab IBM und San und AT&T hatten aber die Unix Quellen in der Hand und konnten bestimmen.

01:27:01.763 --> 01:27:06.730
Es geht nicht, wir brauchen ein eigenes Betriebssystem und das ist dann OSF 1.

01:27:06.770 --> 01:27:12.579
Open Software Foundation gegründet, eigenes Betriebssystem bauen und das war auf Basis von Mach.

01:27:12.619 --> 01:27:14.021
Was war Mach gleich noch?

01:27:14.061 --> 01:27:20.430
Das war ein experimentelles Betriebssystem bei Carnegie Mellon entwickelt auf Basis von Berkeley Unix, also auf Deutsch.

01:27:21.018 --> 01:27:27.265
Die Carnegie Mellon hatte damals Geld von einer DARPA, von einer amerikanischen Verteidigungsbehörde.

01:27:27.325 --> 01:27:33.251
Und die haben gesagt, baut uns ein Betriebssystem für Rechner mit mehreren Prozessoren, also vier oder noch mehr.

01:27:33.331 --> 01:27:34.573
Und da haben die gesagt, wir machen Neues.

01:27:34.613 --> 01:27:41.140
Und da haben die gesagt, bei DARPA, das muss aber UNIX kompatibel sein, also BSD.

01:27:41.160 --> 01:27:47.667
Und so entstand Mach als einen Abklatsch sozusagen und später als Mikrokerntbetriebssystem.

01:27:48.170 --> 01:27:52.034
Wie gesagt, OS F1 auf machbasierend.

01:27:52.074 --> 01:27:53.575
Was ist noch machbasierend?

01:27:53.615 --> 01:27:55.197
Das Mac OS.

01:27:55.217 --> 01:27:57.639
Mac OS ist ja auch so ein Disaster im Prinzip.

01:27:57.699 --> 01:27:59.981
Apple hatte ja Steve Jobs rausgeschmissen.

01:28:00.001 --> 01:28:02.524
Dann haben sie versucht, neues Betriebssystem zu bauen.

01:28:02.564 --> 01:28:06.348
Da gab es dieses BOS gescheitert, noch ein Versuch gescheitert.

01:28:06.388 --> 01:28:08.370
Und dann haben sie Steve Jobs zurückgeholt.

01:28:08.390 --> 01:28:11.092
Der hatte inzwischen neue Firma gegründet, das war Next.

01:28:11.112 --> 01:28:16.017
Und dann wurde Mac OS einfach das Next Step, also das Betriebssystem, was Next gebaut hatte.

01:28:15.997 --> 01:28:26.709
Und so finden wir heute in dem MacOS, was hier rumfährt, immer noch dieses Berkeley Unix und das Mach als Zutaten.

01:28:26.729 --> 01:28:30.093
Windows kommt immer noch nicht vor, weil hier drüben ist die Firma Deck.

01:28:30.113 --> 01:28:37.802
Die Firma Deck hat eigentlich Hardware gebaut und gar keine Betriebssysteme, aber die hatten einen, wie heißt das eigentlich, eine Tauschbörse.

01:28:38.086 --> 01:28:45.037
Der Nutzer haben Software mitgebracht und da gab es so eine Chemie-Bude und die haben Betriebssysteme gebaut, das ist ASX-LFM.

01:28:45.057 --> 01:28:56.074
Und daraus wurde dann das VMS, Virtual Memory System, und daraus wurde dann irgendwann VMS 5.4 und Deck hatte ein Standort in Massachusetts und ein in Seattle.

01:28:56.094 --> 01:29:01.462
Und in Seattle gab es das Projekt, wir packen das VMS auf die Intel-Plattform.

01:29:01.502 --> 01:29:04.026
Und dieses Projekt wurde dann gekanzelt.

01:29:04.664 --> 01:29:13.076
Und daraufhin hat Begetz die Leute von Deck kurzerhand abgeworben, und da haben sie Betriebssystemen gebaut, das ist Windows NT.

01:29:13.116 --> 01:29:19.765
Daraufhin hat Deck natürlich Microsoft verklagt, weil es ist wirklich ganz Frappierend.

01:29:19.785 --> 01:29:25.052
Systemprozesse heißen genauso, das fühlt sich genauso an wie vorerst in frühen Versionen von Windows NT.

01:29:25.808 --> 01:29:31.625
Und den Streit hat man beigelegt, indem man gesagt hat, okay, für Windows sind die Server alles vom Systeme von Deck.

01:29:31.645 --> 01:29:33.791
Wir verkaufen die Dinger jetzt zusammen.

01:29:33.851 --> 01:29:37.783
Und, na ja, den Rest der Geschichte erzähle ich nicht mal.

01:29:38.425 --> 01:29:39.548
Vielen Dank für die Aufmerksamkeit.

